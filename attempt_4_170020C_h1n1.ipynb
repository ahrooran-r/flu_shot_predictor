{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import complete\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "print(\"Import complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Following approach is modeled after this code:\n",
    "https://github.com/Rashmini/Flu-Shot-Learning/blob/master/Random_Forest_Classification/flushot_H1N1_rf.ipynb\n",
    "\n",
    "## Import all the datasets"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train df => rows: 26707, cols: 36\n",
      "train labels df => rows: 26707, cols: 3\n",
      "test df => rows: 26708, cols: 36\n"
     ]
    }
   ],
   "source": [
    "# test data\n",
    "test = pd.read_csv(r\"test_set_features.csv\")\n",
    "\n",
    "# train data\n",
    "train = pd.read_csv(r\"training_set_features.csv\")\n",
    "\n",
    "# target\n",
    "training_labels = pd.read_csv(r\"training_set_labels.csv\")\n",
    "label_h1n1 = training_labels[[\"h1n1_vaccine\"]]\n",
    "\n",
    "# check whether rows are equal\n",
    "print(\"train df => rows: %s, cols: %s\" % (train.shape[0], train.shape[1]))\n",
    "print(\"train labels df => rows: %s, cols: %s\" % (training_labels.shape[0], training_labels.shape[1]))\n",
    "print(\"test df => rows: %s, cols: %s\" % (test.shape[0], test.shape[1]))\n",
    "\n",
    "assert(train.shape[1] == test.shape[1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Pre-processing\n",
    "\n",
    "### Check for duplicates"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duplicates in original training dataset: 0\n",
      "duplicates in label dataset: 0\n",
      "duplicates in original testing dataset: 0\n"
     ]
    }
   ],
   "source": [
    "# check for duplicates\n",
    "original_data_dup_count = np.sum(train.duplicated())\n",
    "label_dup_count = np.sum(training_labels.duplicated())\n",
    "original_test_dup_count = np.sum(test.duplicated())\n",
    "\n",
    "print(\"duplicates in original training dataset: %s\" % original_data_dup_count)\n",
    "print(\"duplicates in label dataset: %s\" % label_dup_count)\n",
    "print(\"duplicates in original testing dataset: %s\" % original_test_dup_count)\n",
    "\n",
    "assert(original_data_dup_count == 0 and label_dup_count == 0 and original_test_dup_count == 0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Setting `respodent_id` as index for the df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "train = train.set_index(\"respondent_id\")\n",
    "test = test.set_index(\"respondent_id\")\n",
    "training_labels = training_labels.set_index(\"respondent_id\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Look for columns with significant amt of null values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 26707 entries, 0 to 26706\n",
      "Data columns (total 35 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   h1n1_concern                 26615 non-null  float64\n",
      " 1   h1n1_knowledge               26591 non-null  float64\n",
      " 2   behavioral_antiviral_meds    26636 non-null  float64\n",
      " 3   behavioral_avoidance         26499 non-null  float64\n",
      " 4   behavioral_face_mask         26688 non-null  float64\n",
      " 5   behavioral_wash_hands        26665 non-null  float64\n",
      " 6   behavioral_large_gatherings  26620 non-null  float64\n",
      " 7   behavioral_outside_home      26625 non-null  float64\n",
      " 8   behavioral_touch_face        26579 non-null  float64\n",
      " 9   doctor_recc_h1n1             24547 non-null  float64\n",
      " 10  doctor_recc_seasonal         24547 non-null  float64\n",
      " 11  chronic_med_condition        25736 non-null  float64\n",
      " 12  child_under_6_months         25887 non-null  float64\n",
      " 13  health_worker                25903 non-null  float64\n",
      " 14  health_insurance             14433 non-null  float64\n",
      " 15  opinion_h1n1_vacc_effective  26316 non-null  float64\n",
      " 16  opinion_h1n1_risk            26319 non-null  float64\n",
      " 17  opinion_h1n1_sick_from_vacc  26312 non-null  float64\n",
      " 18  opinion_seas_vacc_effective  26245 non-null  float64\n",
      " 19  opinion_seas_risk            26193 non-null  float64\n",
      " 20  opinion_seas_sick_from_vacc  26170 non-null  float64\n",
      " 21  age_group                    26707 non-null  object \n",
      " 22  education                    25300 non-null  object \n",
      " 23  race                         26707 non-null  object \n",
      " 24  sex                          26707 non-null  object \n",
      " 25  income_poverty               22284 non-null  object \n",
      " 26  marital_status               25299 non-null  object \n",
      " 27  rent_or_own                  24665 non-null  object \n",
      " 28  employment_status            25244 non-null  object \n",
      " 29  hhs_geo_region               26707 non-null  object \n",
      " 30  census_msa                   26707 non-null  object \n",
      " 31  household_adults             26458 non-null  float64\n",
      " 32  household_children           26458 non-null  float64\n",
      " 33  employment_industry          13377 non-null  object \n",
      " 34  employment_occupation        13237 non-null  object \n",
      "dtypes: float64(23), object(12)\n",
      "memory usage: 7.3+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "I can see that following in training data have severely missing values:\n",
    "1. health_insurance\n",
    "2. employment_industry\n",
    "3. employment_occupation\n",
    "\n",
    "I'm doing the same for test data to see if they match"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 26708 entries, 26707 to 53414\n",
      "Data columns (total 35 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   h1n1_concern                 26623 non-null  float64\n",
      " 1   h1n1_knowledge               26586 non-null  float64\n",
      " 2   behavioral_antiviral_meds    26629 non-null  float64\n",
      " 3   behavioral_avoidance         26495 non-null  float64\n",
      " 4   behavioral_face_mask         26689 non-null  float64\n",
      " 5   behavioral_wash_hands        26668 non-null  float64\n",
      " 6   behavioral_large_gatherings  26636 non-null  float64\n",
      " 7   behavioral_outside_home      26626 non-null  float64\n",
      " 8   behavioral_touch_face        26580 non-null  float64\n",
      " 9   doctor_recc_h1n1             24548 non-null  float64\n",
      " 10  doctor_recc_seasonal         24548 non-null  float64\n",
      " 11  chronic_med_condition        25776 non-null  float64\n",
      " 12  child_under_6_months         25895 non-null  float64\n",
      " 13  health_worker                25919 non-null  float64\n",
      " 14  health_insurance             14480 non-null  float64\n",
      " 15  opinion_h1n1_vacc_effective  26310 non-null  float64\n",
      " 16  opinion_h1n1_risk            26328 non-null  float64\n",
      " 17  opinion_h1n1_sick_from_vacc  26333 non-null  float64\n",
      " 18  opinion_seas_vacc_effective  26256 non-null  float64\n",
      " 19  opinion_seas_risk            26209 non-null  float64\n",
      " 20  opinion_seas_sick_from_vacc  26187 non-null  float64\n",
      " 21  age_group                    26708 non-null  object \n",
      " 22  education                    25301 non-null  object \n",
      " 23  race                         26708 non-null  object \n",
      " 24  sex                          26708 non-null  object \n",
      " 25  income_poverty               22211 non-null  object \n",
      " 26  marital_status               25266 non-null  object \n",
      " 27  rent_or_own                  24672 non-null  object \n",
      " 28  employment_status            25237 non-null  object \n",
      " 29  hhs_geo_region               26708 non-null  object \n",
      " 30  census_msa                   26708 non-null  object \n",
      " 31  household_adults             26483 non-null  float64\n",
      " 32  household_children           26483 non-null  float64\n",
      " 33  employment_industry          13433 non-null  object \n",
      " 34  employment_occupation        13282 non-null  object \n",
      "dtypes: float64(23), object(12)\n",
      "memory usage: 7.3+ MB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here in test data also following have missing values\n",
    "1. health_insurance\n",
    "2. employment_industry\n",
    "3. employment_occupation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# I'm dropping following columns because its not worth for h1n1\n",
    "\n",
    "train = train.drop(\"household_children\", axis=1)\n",
    "test = test.drop(\"household_children\", axis=1)\n",
    "\n",
    "assert (\"household_children\" not in train.columns and \"household_children\" not in test.columns)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Scaling and Encoding data\n",
    "\n",
    "I'm using this answer:\n",
    "https://stackoverflow.com/a/64907828/10582056\n",
    "\n",
    "#### Identifying categorical columns and numerical columns\n",
    "\n",
    "I need to identify categorical columns and unique values for each column."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "categorical_columns = np.where(train.dtypes == object)[0]\n",
    "numerical_columns =  np.where(train.dtypes != object)[0]\n",
    "\n",
    "assert (len(categorical_columns) + len(numerical_columns) == len(train.columns))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As you can see, `employment_industry`, `hhs_geo_region` and `employment_occupation` are scrambled for privacy protection.\n",
    "However, I can still use those columns because, for my use case, knowing actual occupation or industry is not necessary.\n",
    "\n",
    "#### Applying Scaler and Encoding into a pipeline\n",
    "\n",
    "I'm going to use one hot encoding as opposed to label encoding with this one\n",
    "And I'm using Standard scaler as opposed to Min Max Scaler"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# fill numeric values with its mean\n",
    "numeric_preprocessing_steps = Pipeline([\n",
    "    ('standard_scaler', StandardScaler()),\n",
    "    ('simple_imputer', SimpleImputer(strategy = 'mean'))\n",
    "])\n",
    "\n",
    "non_numeric_preprocessing_steps = Pipeline([\n",
    "     ('simple_imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('one_hot_encoder', OneHotEncoder())\n",
    "])\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers = [\n",
    "        ('numeric', numeric_preprocessing_steps, numerical_columns),\n",
    "        ('non_numeric', non_numeric_preprocessing_steps, categorical_columns)\n",
    "    ],\n",
    "    remainder = \"drop\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Attempting to sort with Random Forest Classifier\n",
    "\n",
    "### Split train data into train and test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "(21365, 111)"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split in 80:20 ratio\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train, label_h1n1, test_size=0.2, random_state=42, stratify=label_h1n1)\n",
    "\n",
    "X_train_transform = pd.DataFrame(preprocessor.fit_transform(X_train))\n",
    "X_test_transform =  pd.DataFrame(preprocessor.transform(X_test))\n",
    "\n",
    "assert (X_train_transform.shape[1] == X_test_transform.shape[1])\n",
    "\n",
    "X_train_transform.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# transform whole dataset\n",
    "train_transform = pd.DataFrame(preprocessor.fit_transform(train))\n",
    "test_transform = pd.DataFrame(preprocessor.transform(test))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Use feature engineering with correlation to remove unnecessary features\n",
    "\n",
    "because as you can see there are `112` features now\n",
    "So I need to cut them\n",
    "\n",
    "https://stackoverflow.com/a/60223949/10582056"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "[37, 43, 44, 51, 74, 90, 97]"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setting threshold\n",
    "threshold = 0.84\n",
    "\n",
    "corr = X_train_transform.corr().abs()\n",
    "\n",
    "# this gives a 111 * 111 co-relational matrix\n",
    "\n",
    "# select upper triangle of correlations\n",
    "# because of abs(), both upper and lower triangles have same values\n",
    "upper = corr.where(np.triu(np.ones(corr.shape), k=1).astype(bool))\n",
    "upper.head(2)\n",
    "\n",
    "removed_cols = [column for column in upper.columns if any(upper[column] > threshold)]\n",
    "\n",
    "removed_cols"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Prune columns which have above threshold co-relation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "X_train_transform = X_train_transform.drop(columns = removed_cols)\n",
    "X_test_transform = X_test_transform.drop(columns = removed_cols)\n",
    "\n",
    "train_transform = train_transform.drop(columns = removed_cols)\n",
    "test_transform = test_transform.drop(columns = removed_cols)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Use Randomized Search CV with Random Forest Classifier"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# Use RandomSearchCV to determine K value for each\n",
    "\n",
    "# random_grid = {\n",
    "#     # 'n_estimators': [n for n in range(1, max_val) if n % 10 == 0],\n",
    "#     # 'max_features': ['auto', 'sqrt'],\n",
    "#     # 'max_depth': [n for n in range(0, max_val) if n % 10 == 0] + [None],\n",
    "#     # 'min_samples_split': [n for n in range(0, 30) if n % 2 == 0],\n",
    "#     # 'min_samples_leaf': [n for n in range(0, 30) if n % 2 == 0],\n",
    "#     # 'bootstrap': [True, False]\n",
    "#\n",
    "#     'n_estimators': [n for n in range(1500, 2000) if n % 10 == 0],\n",
    "#     'max_features': ['sqrt', 'auto'],\n",
    "#     'max_depth': [n for n in range(50, 120) if n % 10 == 0] + [None],\n",
    "#     'min_samples_split': [n for n in range(12, 24) if n % 2 == 0],\n",
    "#     'min_samples_leaf': [n for n in range(1, 10)],\n",
    "#     'bootstrap': [False]\n",
    "# }\n",
    "#\n",
    "# rscv = RandomizedSearchCV(\n",
    "#     estimator = RandomForestClassifier(),\n",
    "#     param_distributions = random_grid,\n",
    "#     scoring='roc_auc',\n",
    "#     n_iter=10,\n",
    "#     cv=None,\n",
    "#     verbose=10,\n",
    "#     random_state=42,\n",
    "#     n_jobs=4\n",
    "# )\n",
    "#\n",
    "# print(\"Ready!\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# for h1n1\n",
    "\n",
    "# rscv.fit(X_train_transform, y_train.values.ravel())\n",
    "#\n",
    "# print(rscv.best_params_)\n",
    "# print(rscv.best_score_)\n",
    "# print(rscv.best_estimator_)\n",
    "# print(\"Finished\")\n",
    "\n",
    "# already done. see below for results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "{'n_estimators': 1780, 'min_samples_split': 16, 'min_samples_leaf': 4, 'max_features': 'auto', 'max_depth': 100, 'bootstrap': False}\n",
    "0.8646527299947001\n",
    "\n",
    "### Fine tune with Grid Search CV"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# grid = {\n",
    "#     # 'n_estimators': [n for n in range(1, max_val) if n % 10 == 0],\n",
    "#     # 'max_features': ['auto', 'sqrt'],\n",
    "#     # 'max_depth': [n for n in range(0, max_val) if n % 10 == 0] + [None],\n",
    "#     # 'min_samples_split': [n for n in range(0, 30) if n % 2 == 0],\n",
    "#     # 'min_samples_leaf': [n for n in range(0, 30) if n % 2 == 0],\n",
    "#     # 'bootstrap': [True, False]\n",
    "#\n",
    "#     'n_estimators': [1700, 1780, 1900],\n",
    "#     'max_features': ['auto'],\n",
    "#     'max_depth': [90, 100, 110] + [None],\n",
    "#     'min_samples_split': [12, 16, 20],\n",
    "#     'min_samples_leaf': [3, 4, 5],\n",
    "#     'bootstrap': [False]\n",
    "# }\n",
    "#\n",
    "# gscv = GridSearchCV(\n",
    "#     estimator=RandomForestClassifier(),\n",
    "#     param_grid=grid,\n",
    "#     scoring='roc_auc',\n",
    "#     verbose=10,\n",
    "#     n_jobs=4\n",
    "# )\n",
    "#\n",
    "# print(\"Ready\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "# gscv.fit(X_train_transform, y_train.values.ravel())\n",
    "#\n",
    "# print(grid.best_estimator_)\n",
    "# print(grid.best_params_)\n",
    "# print(grid.best_score_)\n",
    "\n",
    "# print(\"Finished\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train with RandomForestClassifier"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(\n",
    "    n_estimators=1780,\n",
    "    max_features=\"auto\",\n",
    "    max_depth=100,\n",
    "    min_samples_split=16,\n",
    "    min_samples_leaf=4,\n",
    "    bootstrap=False\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H1N1 Fit complete\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.8575340658374075"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.fit(X_train_transform, y_train.values.ravel())\n",
    "print(\"H1N1 Fit complete\")\n",
    "\n",
    "# at this point I got to know that the competition requires probabilities\n",
    "# not labels :(\n",
    "predicted = rfc.predict_proba(X_test_transform)\n",
    "\n",
    "h1n1_predicted = pd.DataFrame( {\n",
    "    \"h1n1_vaccine\": predicted[:, 1],\n",
    "    },\n",
    "    index = y_test.index\n",
    ")\n",
    "\n",
    "assert (h1n1_predicted.shape[1] == 1)\n",
    "\n",
    "roc_auc_score(y_test, h1n1_predicted)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Execute model on given test data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "rfc.fit(train_transform, label_h1n1.values.ravel())\n",
    "h1n1_result = rfc.predict_proba(test_transform)\n",
    "\n",
    "print(\"Done\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26708, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": "   respondent_id  h1n1_vaccine\n0          26707      0.173791\n1          26708      0.045505\n2          26709      0.288724\n3          26710      0.558850\n4          26711      0.319752",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>respondent_id</th>\n      <th>h1n1_vaccine</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>26707</td>\n      <td>0.173791</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>26708</td>\n      <td>0.045505</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>26709</td>\n      <td>0.288724</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>26710</td>\n      <td>0.558850</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>26711</td>\n      <td>0.319752</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "build = pd.DataFrame(test.index)\n",
    "\n",
    "build[\"h1n1_vaccine\"] = h1n1_result[:, 1]\n",
    "\n",
    "print(build.shape)\n",
    "\n",
    "assert (build.shape[0] == len(test.index) and build.shape[1] == 2)\n",
    "\n",
    "build.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Format the table and save it as a csv file"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "# convert to a csv file\n",
    "\n",
    "build.to_csv(\"output.csv\", index=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}