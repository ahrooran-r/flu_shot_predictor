{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import complete\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "print(\"Import complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import all the datasets"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train df => rows: 26707, cols: 36\n",
      "train labels df => rows: 26707, cols: 3\n",
      "test df => rows: 26708, cols: 36\n"
     ]
    }
   ],
   "source": [
    "# test data\n",
    "test = pd.read_csv(r\"test_set_features.csv\")\n",
    "\n",
    "# train data\n",
    "train = pd.read_csv(r\"training_set_features.csv\")\n",
    "\n",
    "# target\n",
    "training_labels = pd.read_csv(r\"training_set_labels.csv\")\n",
    "\n",
    "# check whether rows are equal\n",
    "print(\"train df => rows: %s, cols: %s\" % (train.shape[0], train.shape[1]))\n",
    "print(\"train labels df => rows: %s, cols: %s\" % (training_labels.shape[0], training_labels.shape[1]))\n",
    "print(\"test df => rows: %s, cols: %s\" % (test.shape[0], test.shape[1]))\n",
    "\n",
    "assert(train.shape[1] == test.shape[1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Pre-processing\n",
    "\n",
    "From previous work, it is known that the dataset does not have any\n",
    "duplicates"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Setting `respodent_id` as index for the df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "train = train.set_index(\"respondent_id\")\n",
    "test = test.set_index(\"respondent_id\")\n",
    "training_labels = training_labels.set_index(\"respondent_id\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create a grouped dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data => rows: 53415, cols: 36\n"
     ]
    }
   ],
   "source": [
    "train[\"type\"] = \"train\"\n",
    "test[\"type\"] = \"test\"\n",
    "\n",
    "data_original = pd.concat([train, test], ignore_index=True)\n",
    "\n",
    "# the row count should be total of both df and column count should be incremented by one\n",
    "print(\"data => rows: %s, cols: %s\" % (data_original.shape[0], data_original.shape[1]))\n",
    "\n",
    "assert(data_original.shape[0] == train.shape[0] + test.shape[0])\n",
    "assert(data_original.shape[1] == train.shape[1])\n",
    "\n",
    "del train, test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Look for columns with significant amt of null values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "I can see that following in training data have severely missing values:\n",
    "1. health_insurance\n",
    "2. employment_industry\n",
    "3. employment_occupation\n",
    "\n",
    "I'm doing the same for test data to see if they match\n",
    "\n",
    "Here in test data also following have missing values\n",
    "1. health_insurance\n",
    "2. employment_industry\n",
    "3. employment_occupation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Select important columns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# selected columns\n",
    "# \"type\" column is omitted here, when necessary, it will be brought back\n",
    "selected_features = ['h1n1_concern', 'h1n1_knowledge', 'doctor_recc_h1n1', 'doctor_recc_seasonal',\n",
    "                 'chronic_med_condition', 'opinion_h1n1_vacc_effective', 'opinion_h1n1_risk',\n",
    "                 'opinion_h1n1_sick_from_vacc', 'opinion_seas_vacc_effective', 'opinion_seas_risk',\n",
    "                 'opinion_seas_sick_from_vacc', 'age_group', 'education', 'income_poverty']\n",
    "\n",
    "selected_data = data_original[selected_features]\n",
    "\n",
    "selected_data.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 44,
   "outputs": [
    {
     "data": {
      "text/plain": "(53415, 14)"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age_group', 'education', 'income_poverty']\n",
      "['h1n1_concern', 'h1n1_knowledge', 'doctor_recc_h1n1', 'doctor_recc_seasonal', 'chronic_med_condition', 'opinion_h1n1_vacc_effective', 'opinion_h1n1_risk', 'opinion_h1n1_sick_from_vacc', 'opinion_seas_vacc_effective', 'opinion_seas_risk', 'opinion_seas_sick_from_vacc']\n"
     ]
    }
   ],
   "source": [
    "# divide into numeric columns and categorical columns\n",
    "categorical_columns = np.where(data_original.dtypes == object)[0]\n",
    "categorical_features = [data_original.columns[feature] for feature in categorical_columns]\n",
    "categorical_features = [column for column in categorical_features if column in selected_features]\n",
    "\n",
    "numerical_features = [feat for feat in selected_features if feat not in categorical_features]\n",
    "\n",
    "print(categorical_features)\n",
    "print(numerical_features)\n",
    "\n",
    "assert (len(numerical_features) + len(categorical_features) == len(selected_features))\n",
    "del categorical_columns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Extract columns from data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "data_subset_numeric = data_original.loc[:, numerical_features]\n",
    "data_subset_categorical = data_original.loc[:, categorical_features]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Do scaling with Standard scaler"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "scalar = StandardScaler()\n",
    "data_subset_numeric = pd.DataFrame(scalar.fit_transform(data_subset_numeric), columns = data_subset_numeric.columns)\n",
    "\n",
    "del scalar"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Impute with KNNImputer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "imputer = KNNImputer(n_neighbors=1, missing_values=np.nan)\n",
    "data_subset_numeric = pd.DataFrame(imputer.fit_transform(data_subset_numeric), columns = data_subset_numeric.columns)\n",
    "\n",
    "del imputer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "For categorical data, fill values as \"unknown\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "imputer = SimpleImputer(missing_values=np.nan, strategy='constant', fill_value = 'unknown')\n",
    "data_subset_categorical = pd.DataFrame(imputer.fit_transform(data_subset_categorical), columns = data_subset_categorical.columns)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Rejoining data back into one df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "data = pd.concat([data_subset_numeric, data_subset_categorical], axis = 1)\n",
    "data[\"type\"] = data_original[\"type\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Encoding with LabelEncoding\n",
    "\n",
    "Categorical columns: (except `type`)\n",
    "age_group                       object\n",
    "education                       object\n",
    "income_poverty                  object"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "# change object to category\n",
    "data['age_group'] = data['age_group'].astype('category')\n",
    "data['education'] = data['education'].astype('category')\n",
    "data['income_poverty'] = data['income_poverty'].astype('category')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "`age group: `\n",
    "['18 - 34 Years', '35 - 44 Years', '45 - 54 Years', '55 - 64 Years', '65+ Years']\n",
    "\n",
    "age group in order, hence can be directly label encoded\n",
    "\n",
    "`education: `\n",
    "['12 Years', '< 12 Years', 'College Graduate', 'Some College', 'unknown']\n",
    "\n",
    "education not in order\n",
    "\n",
    "`income_poverty: `\n",
    "['<= $75,000, Above Poverty', '> $75,000', 'Below Poverty', 'unknown']\n",
    "\n",
    "income_poverty not in order"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\OpenSoftware\\miniconda3\\envs\\flu_shot_predictor\\lib\\site-packages\\pandas\\core\\arrays\\categorical.py:2630: FutureWarning: The `inplace` parameter in pandas.Categorical.reorder_categories is deprecated and will be removed in a future version. Removing unused categories will always return a new Categorical object.\n",
      "  res = method(*args, **kwargs)\n",
      "E:\\OpenSoftware\\miniconda3\\envs\\flu_shot_predictor\\lib\\site-packages\\pandas\\core\\arrays\\categorical.py:2630: FutureWarning: The `inplace` parameter in pandas.Categorical.reorder_categories is deprecated and will be removed in a future version. Removing unused categories will always return a new Categorical object.\n",
      "  res = method(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "data['age_group'] = data['age_group'].cat.codes\n",
    "\n",
    "data['education'].cat.reorder_categories(['unknown','< 12 Years', '12 Years', 'Some College', 'College Graduate'], ordered = True, inplace = True)\n",
    "data['education'] = data['education'].cat.codes\n",
    "\n",
    "data['income_poverty'].cat.reorder_categories(['unknown','Below Poverty', '<= $75,000, Above Poverty', '> $75,000'], ordered = True, inplace = True)\n",
    "data['income_poverty'] = data['income_poverty'].cat.codes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "data types of converted columns are in `int8`,\n",
    "convert that to `float64` for consistency"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "for col in data.columns:\n",
    "    if data[col].dtype == 'int8':\n",
    "        data[col] = data[col].astype('float64')\n",
    "\n",
    "assert (not any(data.isna().any()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Attempting to sort with Random Forest Classifier\n",
    "\n",
    "### Split train data into train and test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "# split in 80:20 ratio\n",
    "\n",
    "target_h1n1_vaccine = training_labels[\"h1n1_vaccine\"].values\n",
    "target_seasonal_vaccine = training_labels[\"seasonal_vaccine\"].values\n",
    "\n",
    "train = data[data.type.eq(\"train\")].drop(\"type\", axis=1)\n",
    "test = data[data.type.eq(\"test\")].drop(\"type\", axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    train,\n",
    "    training_labels[['h1n1_vaccine', 'seasonal_vaccine']],\n",
    "    test_size = 0.2,\n",
    "    shuffle = True,\n",
    "    stratify = training_labels[['h1n1_vaccine', 'seasonal_vaccine']],\n",
    "    random_state = 42\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Use feature engineering with correlation to remove unnecessary features\n",
    "\n",
    "https://stackoverflow.com/a/60223949/10582056"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "data": {
      "text/plain": "[]"
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setting threshold\n",
    "threshold = 0.84\n",
    "\n",
    "corr = X_train.corr().abs()\n",
    "upper = corr.where(np.triu(np.ones(corr.shape), k=1).astype(bool))\n",
    "\n",
    "removed_cols = [column for column in upper.columns if any(upper[column] > threshold)]\n",
    "removed_cols"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "no such columns found here\n",
    "\n",
    "### Prune columns which have above threshold co-relation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "# X_train_transform = X_train_transform.drop(columns = removed_cols)\n",
    "# X_test_transform = X_test_transform.drop(columns = removed_cols)\n",
    "#\n",
    "# train_transform = train_transform.drop(columns = removed_cols)\n",
    "# test_transform = test_transform.drop(columns = removed_cols)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Use Randomized Search CV with Random Forest Classifier"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "# Use RandomSearchCV to determine K value for each\n",
    "\n",
    "# random_grid = {\n",
    "#     # 'n_estimators': [n for n in range(1, max_val) if n % 10 == 0],\n",
    "#     # 'max_features': ['auto', 'sqrt'],\n",
    "#     # 'max_depth': [n for n in range(0, max_val) if n % 10 == 0] + [None],\n",
    "#     # 'min_samples_split': [n for n in range(0, 30) if n % 2 == 0],\n",
    "#     # 'min_samples_leaf': [n for n in range(0, 30) if n % 2 == 0],\n",
    "#     # 'bootstrap': [True, False]\n",
    "#\n",
    "#     'n_estimators': [n for n in range(200, 2000) if n % 100 == 0],\n",
    "#     'max_features': ['auto', 'sqrt'],\n",
    "#     'max_depth': [n for n in range(10, 120) if n % 10 == 0] + [None],\n",
    "#     'min_samples_split': [n for n in range(1, 30) if n % 2 == 0],\n",
    "#     'min_samples_leaf': [n for n in range(1, 30) if n % 2 == 0],\n",
    "#     'bootstrap': [True, False]\n",
    "# }\n",
    "#\n",
    "# rscv_h1n1 = RandomizedSearchCV(\n",
    "#     estimator = RandomForestClassifier(),\n",
    "#     param_distributions = random_grid,\n",
    "#     scoring='roc_auc',\n",
    "#     n_iter=10,\n",
    "#     cv=None,\n",
    "#     verbose=2,\n",
    "#     random_state=42,\n",
    "#     n_jobs=-1\n",
    "# )\n",
    "#\n",
    "# rscv_seasonal = deepcopy(rscv_h1n1)\n",
    "#\n",
    "# print(\"Ready!\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "# for h1n1\n",
    "\n",
    "# rscv_h1n1.fit(X_train, y_train['h1n1_vaccine'])\n",
    "#\n",
    "# print(rscv_h1n1.best_params_)\n",
    "# print(rscv_h1n1.best_score_)\n",
    "# print(rscv_h1n1.best_estimator_)\n",
    "# print(\"Finished\")\n",
    "\n",
    "# already done. see below for results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "{'n_estimators': 1780, 'min_samples_split': 16, 'min_samples_leaf': 4, 'max_features': 'auto', 'max_depth': 100, 'bootstrap': False}\n",
    "0.8646527299947001\n",
    "\n",
    "'n_estimators': 200, 'min_samples_split': 8, 'min_samples_leaf': 24, 'max_features': 'auto', 'max_depth': 10, 'bootstrap': False}\n",
    "0.8199652595257858"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "# for seasonal\n",
    "\n",
    "# rscv_seasonal.fit(X_train, y_train['seasonal_vaccine'])\n",
    "#\n",
    "# print(rscv_seasonal.best_params_)\n",
    "# print(rscv_seasonal.best_score_)\n",
    "# print(rscv_seasonal.best_estimator_)\n",
    "# print(\"Finished\")\n",
    "\n",
    "# already done. see below for results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "{'n_estimators': 1780, 'min_samples_split': 16, 'min_samples_leaf': 4, 'max_features': 'auto', 'max_depth': 100, 'bootstrap': False}\n",
    "0.8646527299947001\n",
    "\n",
    "{'n_estimators': 600, 'min_samples_split': 24, 'min_samples_leaf': 16, 'max_features': 'sqrt', 'max_depth': 80, 'bootstrap': True}\n",
    "0.8443021661049906"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Fine tune with Grid Search CV"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [],
   "source": [
    "# grid = {\n",
    "#     # 'n_estimators': [n for n in range(1, max_val) if n % 10 == 0],\n",
    "#     # 'max_features': ['auto', 'sqrt'],\n",
    "#     # 'max_depth': [n for n in range(0, max_val) if n % 10 == 0] + [None],\n",
    "#     # 'min_samples_split': [n for n in range(0, 30) if n % 2 == 0],\n",
    "#     # 'min_samples_leaf': [n for n in range(0, 30) if n % 2 == 0],\n",
    "#     # 'bootstrap': [True, False]\n",
    "#\n",
    "#     'n_estimators': [1700, 1780, 1900],\n",
    "#     'max_features': ['auto'],\n",
    "#     'max_depth': [90, 100, 110] + [None],\n",
    "#     'min_samples_split': [12, 16, 20],\n",
    "#     'min_samples_leaf': [3, 4, 5],\n",
    "#     'bootstrap': [False]\n",
    "# }\n",
    "#\n",
    "# gscv = GridSearchCV(\n",
    "#     estimator=RandomForestClassifier(),\n",
    "#     param_grid=grid,\n",
    "#     scoring='roc_auc',\n",
    "#     verbose=10,\n",
    "#     n_jobs=4\n",
    "# )\n",
    "#\n",
    "# print(\"Ready\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "# gscv.fit(X_train_transform, y_train.values.ravel())\n",
    "#\n",
    "# print(grid.best_estimator_)\n",
    "# print(grid.best_params_)\n",
    "# print(grid.best_score_)\n",
    "\n",
    "# print(\"Finished\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train with RandomForestClassifier"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "rfc_h1n1 = RandomForestClassifier(\n",
    "    n_estimators=1780,\n",
    "    max_features=\"auto\",\n",
    "    max_depth=100,\n",
    "    min_samples_split=16,\n",
    "    min_samples_leaf=4,\n",
    "    bootstrap=False\n",
    ")\n",
    "\n",
    "rfc_seasonal = RandomForestClassifier(\n",
    "    n_estimators=1780,\n",
    "    max_features=\"auto\",\n",
    "    max_depth=100,\n",
    "    min_samples_split=16,\n",
    "    min_samples_leaf=4,\n",
    "    bootstrap=False\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H1N1 Fit complete\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.821942765832905"
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_h1n1.fit(X_train, y_train['h1n1_vaccine'])\n",
    "print(\"H1N1 Fit complete\")\n",
    "\n",
    "predicted = rfc_h1n1.predict_proba(X_test)\n",
    "\n",
    "h1n1_predicted = pd.DataFrame( {\n",
    "    \"h1n1_vaccine\": predicted[:, 1],\n",
    "    },\n",
    "    index = y_test.index\n",
    ")\n",
    "\n",
    "assert (h1n1_predicted.shape[1] == 1)\n",
    "\n",
    "roc_auc_score(y_test[\"h1n1_vaccine\"], h1n1_predicted)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seasonal Fit complete\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.7209534990096823"
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_seasonal.fit(X_train, y_train['seasonal_vaccine'])\n",
    "print(\"Seasonal Fit complete\")\n",
    "\n",
    "predicted = rfc_h1n1.predict_proba(X_test)\n",
    "\n",
    "seasonal_predicted = pd.DataFrame( {\n",
    "    \"seasonal_vaccine\": predicted[:, 1],\n",
    "    },\n",
    "    index = y_test.index\n",
    ")\n",
    "\n",
    "assert (seasonal_predicted.shape[1] == 1)\n",
    "\n",
    "roc_auc_score(y_test[\"seasonal_vaccine\"], seasonal_predicted)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Execute model on given test data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "rfc.fit(train_transform, label_h1n1.values.ravel())\n",
    "h1n1_result = rfc.predict_proba(test_transform)\n",
    "\n",
    "print(\"Done\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26708, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": "   respondent_id  h1n1_vaccine\n0          26707      0.173791\n1          26708      0.045505\n2          26709      0.288724\n3          26710      0.558850\n4          26711      0.319752",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>respondent_id</th>\n      <th>h1n1_vaccine</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>26707</td>\n      <td>0.173791</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>26708</td>\n      <td>0.045505</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>26709</td>\n      <td>0.288724</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>26710</td>\n      <td>0.558850</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>26711</td>\n      <td>0.319752</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "build = pd.DataFrame(test.index)\n",
    "\n",
    "build[\"h1n1_vaccine\"] = h1n1_result[:, 1]\n",
    "\n",
    "print(build.shape)\n",
    "\n",
    "assert (build.shape[0] == len(test.index) and build.shape[1] == 2)\n",
    "\n",
    "build.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Format the table and save it as a csv file"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "# convert to a csv file\n",
    "\n",
    "build.to_csv(\"output.csv\", index=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}