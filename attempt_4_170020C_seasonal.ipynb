{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import complete\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "print(\"Import complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "This is a continuation of `attempt_4_170020C_h1n1.ipynb`, so many\n",
    "checking parts will be removed\n",
    "\n",
    "Run that file before running this\n",
    "\n",
    "## Import all the datasets"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train df => rows: 26707, cols: 35\n",
      "train labels df => rows: 26707, cols: 2\n",
      "test df => rows: 26708, cols: 35\n"
     ]
    }
   ],
   "source": [
    "# test data\n",
    "test = pd.read_csv(r\"test_set_features.csv\", index_col=\"respondent_id\")\n",
    "\n",
    "# train data\n",
    "train = pd.read_csv(r\"training_set_features.csv\", index_col=\"respondent_id\")\n",
    "\n",
    "# target\n",
    "training_labels = pd.read_csv(r\"training_set_labels.csv\", index_col=\"respondent_id\")\n",
    "label_seasonal = training_labels[[\"seasonal_vaccine\"]]\n",
    "\n",
    "# output\n",
    "output = pd.read_csv(r\"output.csv\")\n",
    "\n",
    "# check whether rows are equal\n",
    "print(\"train df => rows: %s, cols: %s\" % (train.shape[0], train.shape[1]))\n",
    "print(\"train labels df => rows: %s, cols: %s\" % (training_labels.shape[0], training_labels.shape[1]))\n",
    "print(\"test df => rows: %s, cols: %s\" % (test.shape[0], test.shape[1]))\n",
    "\n",
    "assert(train.shape[1] == test.shape[1])\n",
    "\n",
    "if \"seasonal_vaccine\" in output.columns:\n",
    "    output = output.drop(columns=[\"seasonal_vaccine\"])\n",
    "\n",
    "assert (list(output.columns) == [\"respondent_id\", \"h1n1_vaccine\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Pre-processing\n",
    "\n",
    "### Scaling and Encoding data\n",
    "\n",
    "#### Identifying categorical columns and numerical columns\n",
    "\n",
    "I need to identify categorical columns and unique values for each column."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "categorical_columns = np.where(train.dtypes == object)[0]\n",
    "numerical_columns =  np.where(train.dtypes != object)[0]\n",
    "\n",
    "assert (len(categorical_columns) + len(numerical_columns) == len(train.columns))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Applying Scaler and Encoding into a pipeline\n",
    "\n",
    "I'm going to use one hot encoding as opposed to label encoding with this one\n",
    "And I'm using Standard scaler as opposed to Min Max Scaler"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# fill numeric values with its mean\n",
    "numeric_preprocessing_steps = Pipeline([\n",
    "    ('standard_scaler', StandardScaler()),\n",
    "    ('simple_imputer', SimpleImputer(strategy = 'mean'))\n",
    "])\n",
    "\n",
    "non_numeric_preprocessing_steps = Pipeline([\n",
    "     ('simple_imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('one_hot_encoder', OneHotEncoder())\n",
    "])\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers = [\n",
    "        ('numeric', numeric_preprocessing_steps, numerical_columns),\n",
    "        ('non_numeric', non_numeric_preprocessing_steps, categorical_columns)\n",
    "    ],\n",
    "    remainder = \"drop\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Attempting to sort with Random Forest Classifier\n",
    "\n",
    "### Split train data into train and test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "(21365, 112)"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split in 80:20 ratio\n",
    "\n",
    "# for seasonal\n",
    "P_train, P_test, q_train, q_test = train_test_split(train, label_seasonal, test_size=0.2, random_state=42, stratify=label_seasonal)\n",
    "\n",
    "# for seasonal\n",
    "P_train_transform = pd.DataFrame(preprocessor.fit_transform(P_train))\n",
    "P_test_transform =  pd.DataFrame(preprocessor.transform(P_test))\n",
    "\n",
    "\n",
    "assert (P_train_transform.shape[1] == P_test_transform.shape[1])\n",
    "\n",
    "P_train_transform.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# transform whole dataset\n",
    "train_transform = pd.DataFrame(preprocessor.fit_transform(train))\n",
    "test_transform = pd.DataFrame(preprocessor.transform(test))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Use feature engineering with correlation to remove unnecessary features\n",
    "\n",
    "because as you can see there are `112` features now\n",
    "So I need to cut them\n",
    "\n",
    "https://stackoverflow.com/a/60223949/10582056"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "[38, 44, 45, 52, 75, 91, 98]"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setting threshold\n",
    "threshold = 0.84\n",
    "\n",
    "corr = P_train_transform.corr().abs()\n",
    "\n",
    "# this gives a 111 * 111 co-relational matrix\n",
    "\n",
    "# select upper triangle of correlations\n",
    "# because of abs(), both upper and lower triangles have same values\n",
    "upper = corr.where(np.triu(np.ones(corr.shape), k=1).astype(bool))\n",
    "upper.head(2)\n",
    "\n",
    "removed_cols = [column for column in upper.columns if any(upper[column] > threshold)]\n",
    "\n",
    "removed_cols"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Prune columns which have above threshold co-relation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "P_train_transform = P_train_transform.drop(columns = removed_cols)\n",
    "P_test_transform = P_test_transform.drop(columns = removed_cols)\n",
    "\n",
    "train_transform = train_transform.drop(columns = removed_cols)\n",
    "test_transform = test_transform.drop(columns = removed_cols)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Use Randomized Search CV with Random Forest Classifier"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready\n"
     ]
    }
   ],
   "source": [
    "# Use RandomSearchCV to determine K value for each\n",
    "\n",
    "# random_grid = {\n",
    "#     # 'n_estimators': [n for n in range(1500, 2000) if n % 10 == 0],\n",
    "#     # 'max_features': ['sqrt', 'auto'],\n",
    "#     # 'max_depth': [n for n in range(50, 120) if n % 10 == 0] + [None],\n",
    "#     # 'min_samples_split': [n for n in range(12, 24) if n % 2 == 0],\n",
    "#     # 'min_samples_leaf': [n for n in range(1, 10)],\n",
    "#     # 'bootstrap': [False]\n",
    "# \n",
    "#     'n_estimators': [1500, 1600, 1700],\n",
    "#     'max_features': ['sqrt', 'auto'],\n",
    "#     'max_depth': [30, 40, 50, 60] + [None],\n",
    "#     'min_samples_split': [20, 22, 24],\n",
    "#     'min_samples_leaf': [1, 3, 5],\n",
    "#     'bootstrap': [True, False]\n",
    "# }\n",
    "# \n",
    "# rscv = RandomizedSearchCV(\n",
    "#     estimator = RandomForestClassifier(),\n",
    "#     param_distributions = random_grid,\n",
    "#     scoring='roc_auc',\n",
    "#     n_iter=10,\n",
    "#     cv=None,\n",
    "#     verbose=10,\n",
    "#     random_state=42,\n",
    "#     n_jobs=4\n",
    "# )\n",
    "# \n",
    "# print(\"Ready\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "{'n_estimators': 1700, 'min_samples_split': 24, 'min_samples_leaf': 1, 'max_features': 'auto', 'max_depth': None, 'bootstrap': False}\n",
      "0.8572862026073617\n",
      "RandomForestClassifier(bootstrap=False, min_samples_split=24, n_estimators=1700)\n",
      "Finished\n"
     ]
    }
   ],
   "source": [
    "# for seasonal\n",
    "\n",
    "# rscv.fit(P_train_transform, q_train.values.ravel())\n",
    "# \n",
    "# print(rscv.best_params_)\n",
    "# print(rscv.best_score_)\n",
    "# print(rscv.best_estimator_)\n",
    "# print(\"Finished\")\n",
    "\n",
    "# already done. see below for results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "{'n_estimators': 1780, 'min_samples_split': 16, 'min_samples_leaf': 4, 'max_features': 'auto', 'max_depth': 100, 'bootstrap': False}\n",
    "0.8566579544610041\n",
    "\n",
    "{'n_estimators': 1600, 'min_samples_split': 22, 'min_samples_leaf': 3, 'max_features': 'sqrt', 'max_depth': 50, 'bootstrap': False}\n",
    "0.8570867758631667\n",
    "\n",
    "{'n_estimators': 1700, 'min_samples_split': 24, 'min_samples_leaf': 1, 'max_features': 'auto', 'max_depth': None, 'bootstrap': False}\n",
    "0.8572862026073617\n",
    "\n",
    "hence it seems I don't have to separately process these two columns\n",
    "\n",
    "### Train with RandomForestClassifier"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(\n",
    "    n_estimators=1700,\n",
    "    max_features=\"auto\",\n",
    "    max_depth=None,\n",
    "    min_samples_split=24,\n",
    "    min_samples_leaf=1,\n",
    "    bootstrap=False\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seasonal Fit complete\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.8593434018014517"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.fit(P_train_transform, q_train.values.ravel())\n",
    "print(\"Seasonal Fit complete\")\n",
    "\n",
    "predicted = rfc.predict_proba(P_test_transform)\n",
    "\n",
    "seasonal_predicted = pd.DataFrame( {\n",
    "    \"seasonal_vaccine\": predicted[:, 1],\n",
    "    },\n",
    "    index = q_test.index\n",
    ")\n",
    "\n",
    "assert (seasonal_predicted.shape[1] == 1)\n",
    "\n",
    "roc_auc_score(q_test, seasonal_predicted)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Execute model on given test data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "rfc.fit(train_transform, label_seasonal.values.ravel())\n",
    "seasonal_result = rfc.predict_proba(test_transform)\n",
    "\n",
    "print(\"Done\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26708, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": "   respondent_id  h1n1_vaccine  seasonal_vaccine\n0          26707      0.173791          0.340573\n1          26708      0.045505          0.085706",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>respondent_id</th>\n      <th>h1n1_vaccine</th>\n      <th>seasonal_vaccine</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>26707</td>\n      <td>0.173791</td>\n      <td>0.340573</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>26708</td>\n      <td>0.045505</td>\n      <td>0.085706</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "build = pd.DataFrame(test.index)\n",
    "\n",
    "build[\"h1n1_vaccine\"] = output[\"h1n1_vaccine\"]\n",
    "build[\"seasonal_vaccine\"] = seasonal_result[:, 1]\n",
    "\n",
    "print(build.shape)\n",
    "\n",
    "assert (build.shape[0] == len(test.index) and build.shape[1] == 3)\n",
    "\n",
    "build.head(2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Format the table and save it as a csv file"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# convert to a csv file\n",
    "\n",
    "build.to_csv(\"output.csv\", index=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}