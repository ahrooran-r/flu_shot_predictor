{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from Util import LabelEncoderWithMissingValues\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Import all the datasets"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train df => rows: 26707, cols: 36\n",
      "train labels df => rows: 26707, cols: 3\n",
      "test df => rows: 26708, cols: 36\n"
     ]
    }
   ],
   "source": [
    "# test data\n",
    "original_test = pd.read_csv(r\"test_set_features.csv\")\n",
    "\n",
    "# train data\n",
    "original_train = pd.read_csv(r\"training_set_features.csv\")\n",
    "\n",
    "#target\n",
    "training_labels = pd.read_csv(r\"training_set_labels.csv\")\n",
    "\n",
    "# check whether rows are equal\n",
    "print(\"train df => rows: %s, cols: %s\" % (original_train.shape[0], original_train.shape[1]))\n",
    "print(\"train labels df => rows: %s, cols: %s\" % (training_labels.shape[0], training_labels.shape[1]))\n",
    "print(\"test df => rows: %s, cols: %s\" % (original_test.shape[0], original_test.shape[1]))\n",
    "\n",
    "assert(original_train.shape[1] == original_test.shape[1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Data cleaning\n",
    "\n",
    "### 2.1 Check for duplicates"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duplicates in original training dataset: 0\n",
      "duplicates in label dataset: 0\n",
      "duplicates in original testing dataset: 0\n"
     ]
    }
   ],
   "source": [
    "# check for duplicates\n",
    "original_data_dup_count = np.sum(original_train.duplicated())\n",
    "label_dup_count = np.sum(training_labels.duplicated())\n",
    "original_test_dup_count = np.sum(original_test.duplicated())\n",
    "\n",
    "print(\"duplicates in original training dataset: %s\" % original_data_dup_count)\n",
    "print(\"duplicates in label dataset: %s\" % label_dup_count)\n",
    "print(\"duplicates in original testing dataset: %s\" % original_test_dup_count)\n",
    "\n",
    "assert(original_data_dup_count == 0 and label_dup_count == 0 and original_test_dup_count == 0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.2 Merging both train and test datasets\n",
    "\n",
    "Before starting data cleaning, I need to merge them together for consistent results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data => rows: 53415, cols: 37\n"
     ]
    }
   ],
   "source": [
    "original_train[\"type\"] = \"train\"\n",
    "original_test[\"type\"] = \"test\"\n",
    "original_data = pd.concat([original_train, original_test], ignore_index=True)\n",
    "\n",
    "# the row count should be doubled and column count should be incremented by one\n",
    "print(\"data => rows: %s, cols: %s\" % (original_data.shape[0], original_data.shape[1]))\n",
    "\n",
    "assert(original_data.shape[0] == original_train.shape[0] + original_test.shape[0])\n",
    "assert(original_data.shape[1] == original_train.shape[1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now `data` df has both datasets with different `Type` feature\n",
    "\n",
    "Since there are no duplicates in the dataset, no need to drop duplicates\n",
    "\n",
    "Before continuing, I'm setting `respondent_id` as index for the df\n",
    "\n",
    "### 2.3 Setting `respodent_id` as index for the df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "outputs": [
    {
     "data": {
      "text/plain": "               h1n1_concern  h1n1_knowledge  behavioral_antiviral_meds  \\\nrespondent_id                                                            \n0                       1.0             0.0                        0.0   \n1                       3.0             2.0                        0.0   \n\n               behavioral_avoidance  behavioral_face_mask  \\\nrespondent_id                                               \n0                               0.0                   0.0   \n1                               1.0                   0.0   \n\n               behavioral_wash_hands  behavioral_large_gatherings  \\\nrespondent_id                                                       \n0                                0.0                          0.0   \n1                                1.0                          0.0   \n\n               behavioral_outside_home  behavioral_touch_face  \\\nrespondent_id                                                   \n0                                  1.0                    1.0   \n1                                  1.0                    1.0   \n\n               doctor_recc_h1n1  ...  marital_status  rent_or_own  \\\nrespondent_id                    ...                                \n0                           0.0  ...     Not Married          Own   \n1                           0.0  ...     Not Married         Rent   \n\n                employment_status  hhs_geo_region                census_msa  \\\nrespondent_id                                                                 \n0              Not in Labor Force        oxchjgsf                   Non-MSA   \n1                        Employed        bhuqouqj  MSA, Not Principle  City   \n\n               household_adults  household_children  employment_industry  \\\nrespondent_id                                                              \n0                           0.0                 0.0                  NaN   \n1                           0.0                 0.0             pxcmvdjn   \n\n               employment_occupation   type  \nrespondent_id                                \n0                                NaN  train  \n1                           xgwztkwe  train  \n\n[2 rows x 36 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>h1n1_concern</th>\n      <th>h1n1_knowledge</th>\n      <th>behavioral_antiviral_meds</th>\n      <th>behavioral_avoidance</th>\n      <th>behavioral_face_mask</th>\n      <th>behavioral_wash_hands</th>\n      <th>behavioral_large_gatherings</th>\n      <th>behavioral_outside_home</th>\n      <th>behavioral_touch_face</th>\n      <th>doctor_recc_h1n1</th>\n      <th>...</th>\n      <th>marital_status</th>\n      <th>rent_or_own</th>\n      <th>employment_status</th>\n      <th>hhs_geo_region</th>\n      <th>census_msa</th>\n      <th>household_adults</th>\n      <th>household_children</th>\n      <th>employment_industry</th>\n      <th>employment_occupation</th>\n      <th>type</th>\n    </tr>\n    <tr>\n      <th>respondent_id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>Not Married</td>\n      <td>Own</td>\n      <td>Not in Labor Force</td>\n      <td>oxchjgsf</td>\n      <td>Non-MSA</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>Not Married</td>\n      <td>Rent</td>\n      <td>Employed</td>\n      <td>bhuqouqj</td>\n      <td>MSA, Not Principle  City</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>pxcmvdjn</td>\n      <td>xgwztkwe</td>\n      <td>train</td>\n    </tr>\n  </tbody>\n</table>\n<p>2 rows × 36 columns</p>\n</div>"
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set `respondent_id` as index\n",
    "data = original_data.set_index(\"respondent_id\")\n",
    "training_labels = training_labels.set_index(\"respondent_id\")\n",
    "\n",
    "data.head(2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.4 Encoding categorical data\n",
    "\n",
    "This was not done in `attempt_1_170020C`. I am going with LabelEncoder to encode categorical features.\n",
    "For that, I need to know what are the categorical features.\n",
    "\n",
    "#### 2.4.1 Identifying categorical columns\n",
    "\n",
    "I need to identify categorical columns and unique values for each column."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age_group:\t['55 - 64 Years' '35 - 44 Years' '18 - 34 Years' '65+ Years'\n",
      " '45 - 54 Years']\n",
      "education:\t['< 12 Years' '12 Years' 'College Graduate' 'Some College' nan]\n",
      "race:\t['White' 'Black' 'Other or Multiple' 'Hispanic']\n",
      "sex:\t['Female' 'Male']\n",
      "income_poverty:\t['Below Poverty' '<= $75,000, Above Poverty' '> $75,000' nan]\n",
      "marital_status:\t['Not Married' 'Married' nan]\n",
      "rent_or_own:\t['Own' 'Rent' nan]\n",
      "employment_status:\t['Not in Labor Force' 'Employed' 'Unemployed' nan]\n",
      "hhs_geo_region:\t['oxchjgsf' 'bhuqouqj' 'qufhixun' 'lrircsnp' 'atmpeygn' 'lzgpxyit'\n",
      " 'fpwskwrf' 'mlyzmhmf' 'dqpwygqj' 'kbazzjca']\n",
      "census_msa:\t['Non-MSA' 'MSA, Not Principle  City' 'MSA, Principle City']\n",
      "employment_industry:\t[nan 'pxcmvdjn' 'rucpziij' 'wxleyezf' 'saaquncn' 'xicduogh' 'ldnlellj'\n",
      " 'wlfvacwt' 'nduyfdeo' 'fcxhlnwr' 'vjjrobsf' 'arjwrbjb' 'atmlpfrs'\n",
      " 'msuufmds' 'xqicxuve' 'phxvnwax' 'dotnnunm' 'mfikgejo' 'cfqqtusy'\n",
      " 'mcubkhph' 'haxffmxo' 'qnlwzans']\n",
      "employment_occupation:\t[nan 'xgwztkwe' 'xtkaffoo' 'emcorrxb' 'vlluhbov' 'xqwwgdyp' 'ccgxvspp'\n",
      " 'qxajmpny' 'kldqjyjy' 'mxkfnird' 'hfxkjkmi' 'bxpfxfdn' 'ukymxvdu'\n",
      " 'cmhcxjea' 'haliazsg' 'dlvbwzss' 'xzmlyyjv' 'oijqvulv' 'rcertsgn'\n",
      " 'tfqavkke' 'hodpvpew' 'uqqtjvyb' 'pvmttkik' 'dcjcmpih']\n",
      "type:\t['train' 'test']\n"
     ]
    }
   ],
   "source": [
    "categorical_columns = np.where(data.dtypes == object)[0]\n",
    "\n",
    "categorical_features = [data.columns[feature] for feature in categorical_columns]\n",
    "\n",
    "for feature in categorical_features:\n",
    "    print(\"%s:\\t%s\" % (feature, str(data[feature].unique())))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As you can see, `employment_industry`, `hhs_geo_region` and `employment_occupation` are scrambled for privacy protection.\n",
    "However, I can still use those columns because, for my use case, knowing actual occupation or industry is not necessary.\n",
    "\n",
    "Now I can apply LabelEncoding to those columns, because `NaN` values are depicted as `NaN`\n",
    "\n",
    "#### 2.4.2 Applying Label Encoding to categorical columns\n",
    "\n",
    "The problem with Native encoder is that it also encodes `NaN` values.\n",
    "I have to make sure `Nan` values are unaffected as I'll be sanitizing them later"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "outputs": [
    {
     "data": {
      "text/plain": "               h1n1_concern  h1n1_knowledge  behavioral_antiviral_meds  \\\nrespondent_id                                                            \n53413                   3.0             1.0                        0.0   \n53414                   2.0             1.0                        0.0   \n\n               behavioral_avoidance  behavioral_face_mask  \\\nrespondent_id                                               \n53413                           1.0                   0.0   \n53414                           0.0                   0.0   \n\n               behavioral_wash_hands  behavioral_large_gatherings  \\\nrespondent_id                                                       \n53413                            1.0                          0.0   \n53414                            1.0                          0.0   \n\n               behavioral_outside_home  behavioral_touch_face  \\\nrespondent_id                                                   \n53413                              1.0                    0.0   \n53414                              0.0                    1.0   \n\n               doctor_recc_h1n1  ...  marital_status  rent_or_own  \\\nrespondent_id                    ...                                \n53413                       0.0  ...             1.0          0.0   \n53414                       1.0  ...             0.0          1.0   \n\n               employment_status  hhs_geo_region  census_msa  \\\nrespondent_id                                                  \n53413                        0.0             1.0         1.0   \n53414                        1.0             3.0         2.0   \n\n               household_adults  household_children  employment_industry  \\\nrespondent_id                                                              \n53413                       1.0                 0.0                  NaN   \n53414                       0.0                 0.0                  NaN   \n\n               employment_occupation  type  \nrespondent_id                               \n53413                            NaN  test  \n53414                            2.0  test  \n\n[2 rows x 36 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>h1n1_concern</th>\n      <th>h1n1_knowledge</th>\n      <th>behavioral_antiviral_meds</th>\n      <th>behavioral_avoidance</th>\n      <th>behavioral_face_mask</th>\n      <th>behavioral_wash_hands</th>\n      <th>behavioral_large_gatherings</th>\n      <th>behavioral_outside_home</th>\n      <th>behavioral_touch_face</th>\n      <th>doctor_recc_h1n1</th>\n      <th>...</th>\n      <th>marital_status</th>\n      <th>rent_or_own</th>\n      <th>employment_status</th>\n      <th>hhs_geo_region</th>\n      <th>census_msa</th>\n      <th>household_adults</th>\n      <th>household_children</th>\n      <th>employment_industry</th>\n      <th>employment_occupation</th>\n      <th>type</th>\n    </tr>\n    <tr>\n      <th>respondent_id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>53413</th>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>test</td>\n    </tr>\n    <tr>\n      <th>53414</th>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>test</td>\n    </tr>\n  </tbody>\n</table>\n<p>2 rows × 36 columns</p>\n</div>"
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder, data = LabelEncoderWithMissingValues().categorical_to_numeric(data, ignored=['type'])\n",
    "\n",
    "assert(data.shape[1] == original_data.shape[1] - 1)\n",
    "\n",
    "data.tail(2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As you can see `data` is now encoded with the exception of `type` column.\n",
    "The type column will be later used to divide `data` into `train` and\n",
    "`test`\n",
    "\n",
    "### 2.5 Filling missing values\n",
    "\n",
    "I want to use Nearest Neighbor Imputation to fill `NaN` values\n",
    "\n",
    "#### 2.5.1 Normalizing data\n",
    "\n",
    "KNN Imputer is distance based, and hence data should be normalized beforehand to avoid\n",
    "bias."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "outputs": [
    {
     "data": {
      "text/plain": "   h1n1_concern  h1n1_knowledge  behavioral_antiviral_meds  \\\n0      0.333333             0.0                        0.0   \n1      1.000000             1.0                        0.0   \n2      0.333333             0.5                        0.0   \n3      0.333333             0.5                        0.0   \n4      0.666667             0.5                        0.0   \n\n   behavioral_avoidance  behavioral_face_mask  behavioral_wash_hands  \\\n0                   0.0                   0.0                    0.0   \n1                   1.0                   0.0                    1.0   \n2                   1.0                   0.0                    0.0   \n3                   1.0                   0.0                    1.0   \n4                   1.0                   0.0                    1.0   \n\n   behavioral_large_gatherings  behavioral_outside_home  \\\n0                          0.0                      1.0   \n1                          0.0                      1.0   \n2                          0.0                      0.0   \n3                          1.0                      0.0   \n4                          1.0                      0.0   \n\n   behavioral_touch_face  doctor_recc_h1n1  ...  income_poverty  \\\n0                    1.0               0.0  ...             0.0   \n1                    1.0               0.0  ...             0.0   \n2                    0.0               NaN  ...             0.5   \n3                    0.0               0.0  ...             0.0   \n4                    1.0               0.0  ...             0.5   \n\n   marital_status  rent_or_own  employment_status  hhs_geo_region  census_msa  \\\n0             0.0          0.0                0.0        0.000000         0.0   \n1             0.0          1.0                0.5        0.111111         0.5   \n2             0.0          0.0                0.5        0.222222         0.5   \n3             0.0          1.0                0.0        0.333333         1.0   \n4             1.0          0.0                0.5        0.222222         0.5   \n\n   household_adults  household_children  employment_industry  \\\n0          0.000000                 0.0                  NaN   \n1          0.000000                 0.0                 0.00   \n2          0.666667                 0.0                 0.05   \n3          0.000000                 0.0                  NaN   \n4          0.333333                 0.0                 0.10   \n\n   employment_occupation  \n0                    NaN  \n1               0.000000  \n2               0.045455  \n3                    NaN  \n4               0.090909  \n\n[5 rows x 35 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>h1n1_concern</th>\n      <th>h1n1_knowledge</th>\n      <th>behavioral_antiviral_meds</th>\n      <th>behavioral_avoidance</th>\n      <th>behavioral_face_mask</th>\n      <th>behavioral_wash_hands</th>\n      <th>behavioral_large_gatherings</th>\n      <th>behavioral_outside_home</th>\n      <th>behavioral_touch_face</th>\n      <th>doctor_recc_h1n1</th>\n      <th>...</th>\n      <th>income_poverty</th>\n      <th>marital_status</th>\n      <th>rent_or_own</th>\n      <th>employment_status</th>\n      <th>hhs_geo_region</th>\n      <th>census_msa</th>\n      <th>household_adults</th>\n      <th>household_children</th>\n      <th>employment_industry</th>\n      <th>employment_occupation</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.333333</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.000000</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.5</td>\n      <td>0.111111</td>\n      <td>0.5</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.333333</td>\n      <td>0.5</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>0.5</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.5</td>\n      <td>0.222222</td>\n      <td>0.5</td>\n      <td>0.666667</td>\n      <td>0.0</td>\n      <td>0.05</td>\n      <td>0.045455</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.333333</td>\n      <td>0.5</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.333333</td>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.666667</td>\n      <td>0.5</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.5</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.5</td>\n      <td>0.222222</td>\n      <td>0.5</td>\n      <td>0.333333</td>\n      <td>0.0</td>\n      <td>0.10</td>\n      <td>0.090909</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 35 columns</p>\n</div>"
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = data.drop(\"type\", axis=1)\n",
    "\n",
    "scalar = MinMaxScaler()\n",
    "temp = pd.DataFrame(scalar.fit_transform(temp), columns=temp.columns)\n",
    "\n",
    "# note that `temp` has column `type` missing\n",
    "temp.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.5.2 Utilizing KNN Imputer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "outputs": [
    {
     "data": {
      "text/plain": "       h1n1_concern  h1n1_knowledge  behavioral_antiviral_meds  \\\n53410      0.333333             0.5                        0.0   \n53411      1.000000             0.5                        0.0   \n53412      0.000000             0.5                        0.0   \n53413      1.000000             0.5                        0.0   \n53414      0.666667             0.5                        0.0   \n\n       behavioral_avoidance  behavioral_face_mask  behavioral_wash_hands  \\\n53410                   1.0                   0.0                    1.0   \n53411                   1.0                   0.0                    1.0   \n53412                   0.0                   0.0                    0.0   \n53413                   1.0                   0.0                    1.0   \n53414                   0.0                   0.0                    1.0   \n\n       behavioral_large_gatherings  behavioral_outside_home  \\\n53410                          0.0                      0.0   \n53411                          1.0                      1.0   \n53412                          0.0                      0.0   \n53413                          0.0                      1.0   \n53414                          0.0                      0.0   \n\n       behavioral_touch_face  doctor_recc_h1n1  ...  marital_status  \\\n53410                    1.0               1.0  ...        0.764706   \n53411                    1.0               0.0  ...        1.000000   \n53412                    0.0               0.0  ...        0.000000   \n53413                    0.0               0.0  ...        1.000000   \n53414                    1.0               1.0  ...        0.000000   \n\n       rent_or_own  employment_status  hhs_geo_region  census_msa  \\\n53410     0.411765           0.352941        0.888889         1.0   \n53411     1.000000           0.500000        0.222222         0.0   \n53412     1.000000           0.000000        0.222222         0.5   \n53413     0.000000           0.000000        0.111111         0.5   \n53414     1.000000           0.500000        0.333333         1.0   \n\n       household_adults  household_children  employment_industry  \\\n53410          0.333333            0.333333             0.408824   \n53411          0.333333            1.000000             0.400000   \n53412          0.333333            0.000000             0.252941   \n53413          0.333333            0.000000             0.447059   \n53414          0.000000            0.000000             0.320588   \n\n       employment_occupation  type  \n53410               0.304813  test  \n53411               0.136364  test  \n53412               0.288770  test  \n53413               0.294118  test  \n53414               0.045455  test  \n\n[5 rows x 36 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>h1n1_concern</th>\n      <th>h1n1_knowledge</th>\n      <th>behavioral_antiviral_meds</th>\n      <th>behavioral_avoidance</th>\n      <th>behavioral_face_mask</th>\n      <th>behavioral_wash_hands</th>\n      <th>behavioral_large_gatherings</th>\n      <th>behavioral_outside_home</th>\n      <th>behavioral_touch_face</th>\n      <th>doctor_recc_h1n1</th>\n      <th>...</th>\n      <th>marital_status</th>\n      <th>rent_or_own</th>\n      <th>employment_status</th>\n      <th>hhs_geo_region</th>\n      <th>census_msa</th>\n      <th>household_adults</th>\n      <th>household_children</th>\n      <th>employment_industry</th>\n      <th>employment_occupation</th>\n      <th>type</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>53410</th>\n      <td>0.333333</td>\n      <td>0.5</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.764706</td>\n      <td>0.411765</td>\n      <td>0.352941</td>\n      <td>0.888889</td>\n      <td>1.0</td>\n      <td>0.333333</td>\n      <td>0.333333</td>\n      <td>0.408824</td>\n      <td>0.304813</td>\n      <td>test</td>\n    </tr>\n    <tr>\n      <th>53411</th>\n      <td>1.000000</td>\n      <td>0.5</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.500000</td>\n      <td>0.222222</td>\n      <td>0.0</td>\n      <td>0.333333</td>\n      <td>1.000000</td>\n      <td>0.400000</td>\n      <td>0.136364</td>\n      <td>test</td>\n    </tr>\n    <tr>\n      <th>53412</th>\n      <td>0.000000</td>\n      <td>0.5</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.222222</td>\n      <td>0.5</td>\n      <td>0.333333</td>\n      <td>0.000000</td>\n      <td>0.252941</td>\n      <td>0.288770</td>\n      <td>test</td>\n    </tr>\n    <tr>\n      <th>53413</th>\n      <td>1.000000</td>\n      <td>0.5</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.111111</td>\n      <td>0.5</td>\n      <td>0.333333</td>\n      <td>0.000000</td>\n      <td>0.447059</td>\n      <td>0.294118</td>\n      <td>test</td>\n    </tr>\n    <tr>\n      <th>53414</th>\n      <td>0.666667</td>\n      <td>0.5</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.500000</td>\n      <td>0.333333</td>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.320588</td>\n      <td>0.045455</td>\n      <td>test</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 36 columns</p>\n</div>"
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# got the neighbour value `n_neighbors` from `attempt_1_170020C`\n",
    "imputer = KNNImputer(n_neighbors=17)\n",
    "\n",
    "temp = pd.DataFrame(imputer.fit_transform(temp), columns=temp.columns)\n",
    "\n",
    "temp[\"type\"] = data[\"type\"]\n",
    "data = temp\n",
    "\n",
    "assert (not any(data.isna().any()))\n",
    "\n",
    "data.tail()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.6 Attempting to sort with K Neighbours Classifier\n",
    "\n",
    "This is same classifier as `attempt_1_170020C`\n",
    "\n",
    "#### 2.6.1 Define targets and train, test data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "outputs": [],
   "source": [
    "target_h1n1_vaccine = training_labels[\"h1n1_vaccine\"].values\n",
    "target_seasonal_vaccine = training_labels[\"seasonal_vaccine\"].values\n",
    "\n",
    "train_data = data[data.type.eq(\"train\")].drop(\"type\", axis=1)\n",
    "test_data = data[data.type.eq(\"test\")].drop(\"type\", axis=1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.6.2 Split train data into train and test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "outputs": [],
   "source": [
    "# split in 80:20 ratio\n",
    "# because of two separate train and test scenarios, I'm using different names rather than use X_train, X_test...\n",
    "p_train, p_test, q_train, q_test = train_test_split(train_data, target_h1n1_vaccine, test_size=0.2, random_state=1, stratify=target_h1n1_vaccine)\n",
    "r_train, r_test, s_train, s_test = train_test_split(train_data, target_seasonal_vaccine, test_size=0.2, random_state=1, stratify=target_seasonal_vaccine)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.6.3 Use Grid Search CV\n",
    "\n",
    "with K Neighbors Classifier separately for both h1n1 vaccine and seasonal vaccine"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "outputs": [],
   "source": [
    "#### Use Grid Search to determine K value for each\n",
    "\n",
    "param_grid = {\n",
    "    \"n_neighbors\": [3, 5, 17, 21],\n",
    "    \"weights\": [\"uniform\", \"distance\"],\n",
    "    \"metric\": [\"euclidean\", \"manhattan\"]\n",
    "}\n",
    "gscv = GridSearchCV(KNeighborsClassifier(), param_grid, verbose=1, cv=3, n_jobs=-1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "{'metric': 'manhattan', 'n_neighbors': 21, 'weights': 'distance'}\n",
      "0.8222793339869369\n",
      "KNeighborsClassifier(metric='manhattan', n_neighbors=21, weights='distance')\n"
     ]
    }
   ],
   "source": [
    "# for h1n1 vaccine\n",
    "\n",
    "gscv.fit(p_train, q_train)\n",
    "\n",
    "print(gscv.best_params_)\n",
    "print(gscv.best_score_)\n",
    "print(gscv.best_estimator_)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "{'metric': 'manhattan', 'n_neighbors': 21, 'weights': 'distance'}\n",
      "0.8222793339869369\n",
      "KNeighborsClassifier(metric='manhattan', n_neighbors=21, weights='distance')\n"
     ]
    }
   ],
   "source": [
    "# for seasonal vaccine\n",
    "gscv.fit(p_train, q_train)\n",
    "\n",
    "print(gscv.best_params_)\n",
    "print(gscv.best_score_)\n",
    "print(gscv.best_estimator_)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}