{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import complete.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from Util import LabelEncoderWithMissingValues\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "print(\"Import complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import all the datasets"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train df => rows: 26707, cols: 36\n",
      "train labels df => rows: 26707, cols: 3\n",
      "test df => rows: 26708, cols: 36\n"
     ]
    }
   ],
   "source": [
    "# test data\n",
    "original_test = pd.read_csv(r\"test_set_features.csv\")\n",
    "\n",
    "# train data\n",
    "original_train = pd.read_csv(r\"training_set_features.csv\")\n",
    "\n",
    "#target\n",
    "training_labels = pd.read_csv(r\"training_set_labels.csv\")\n",
    "\n",
    "# check whether rows are equal\n",
    "print(\"train df => rows: %s, cols: %s\" % (original_train.shape[0], original_train.shape[1]))\n",
    "print(\"train labels df => rows: %s, cols: %s\" % (training_labels.shape[0], training_labels.shape[1]))\n",
    "print(\"test df => rows: %s, cols: %s\" % (original_test.shape[0], original_test.shape[1]))\n",
    "\n",
    "assert(original_train.shape[1] == original_test.shape[1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Analyse dataset\n",
    "\n",
    "### Check for duplicates"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duplicates in original training dataset: 0\n",
      "duplicates in label dataset: 0\n",
      "duplicates in original testing dataset: 0\n"
     ]
    }
   ],
   "source": [
    "# check for duplicates\n",
    "original_data_dup_count = np.sum(original_train.duplicated())\n",
    "label_dup_count = np.sum(training_labels.duplicated())\n",
    "original_test_dup_count = np.sum(original_test.duplicated())\n",
    "\n",
    "print(\"duplicates in original training dataset: %s\" % original_data_dup_count)\n",
    "print(\"duplicates in label dataset: %s\" % label_dup_count)\n",
    "print(\"duplicates in original testing dataset: %s\" % original_test_dup_count)\n",
    "\n",
    "assert(original_data_dup_count == 0 and label_dup_count == 0 and original_test_dup_count == 0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Merging both train and test data sets\n",
    "\n",
    "Before starting data cleaning, I need to merge them together for consistent results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data => rows: 53415, cols: 37\n"
     ]
    }
   ],
   "source": [
    "original_train[\"type\"] = \"train\"\n",
    "original_test[\"type\"] = \"test\"\n",
    "original_data = pd.concat([original_train, original_test], ignore_index=True)\n",
    "\n",
    "# the row count should be total of both df and column count should be incremented by one\n",
    "print(\"data => rows: %s, cols: %s\" % (original_data.shape[0], original_data.shape[1]))\n",
    "\n",
    "assert(original_data.shape[0] == original_train.shape[0] + original_test.shape[0])\n",
    "assert(original_data.shape[1] == original_train.shape[1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now `data` df has both data sets with different `Type` feature\n",
    "\n",
    "Since there are no duplicates in the dataset, no need to drop duplicates\n",
    "\n",
    "Before continuing, I'm setting `respondent_id` as index for the df\n",
    "\n",
    "### Setting `respodent_id` as index for the df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "data": {
      "text/plain": "               h1n1_concern  h1n1_knowledge  behavioral_antiviral_meds  \\\nrespondent_id                                                            \n0                       1.0             0.0                        0.0   \n1                       3.0             2.0                        0.0   \n\n               behavioral_avoidance  behavioral_face_mask  \\\nrespondent_id                                               \n0                               0.0                   0.0   \n1                               1.0                   0.0   \n\n               behavioral_wash_hands  behavioral_large_gatherings  \\\nrespondent_id                                                       \n0                                0.0                          0.0   \n1                                1.0                          0.0   \n\n               behavioral_outside_home  behavioral_touch_face  \\\nrespondent_id                                                   \n0                                  1.0                    1.0   \n1                                  1.0                    1.0   \n\n               doctor_recc_h1n1  ...  marital_status  rent_or_own  \\\nrespondent_id                    ...                                \n0                           0.0  ...     Not Married          Own   \n1                           0.0  ...     Not Married         Rent   \n\n                employment_status  hhs_geo_region                census_msa  \\\nrespondent_id                                                                 \n0              Not in Labor Force        oxchjgsf                   Non-MSA   \n1                        Employed        bhuqouqj  MSA, Not Principle  City   \n\n               household_adults  household_children  employment_industry  \\\nrespondent_id                                                              \n0                           0.0                 0.0                  NaN   \n1                           0.0                 0.0             pxcmvdjn   \n\n               employment_occupation   type  \nrespondent_id                                \n0                                NaN  train  \n1                           xgwztkwe  train  \n\n[2 rows x 36 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>h1n1_concern</th>\n      <th>h1n1_knowledge</th>\n      <th>behavioral_antiviral_meds</th>\n      <th>behavioral_avoidance</th>\n      <th>behavioral_face_mask</th>\n      <th>behavioral_wash_hands</th>\n      <th>behavioral_large_gatherings</th>\n      <th>behavioral_outside_home</th>\n      <th>behavioral_touch_face</th>\n      <th>doctor_recc_h1n1</th>\n      <th>...</th>\n      <th>marital_status</th>\n      <th>rent_or_own</th>\n      <th>employment_status</th>\n      <th>hhs_geo_region</th>\n      <th>census_msa</th>\n      <th>household_adults</th>\n      <th>household_children</th>\n      <th>employment_industry</th>\n      <th>employment_occupation</th>\n      <th>type</th>\n    </tr>\n    <tr>\n      <th>respondent_id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>Not Married</td>\n      <td>Own</td>\n      <td>Not in Labor Force</td>\n      <td>oxchjgsf</td>\n      <td>Non-MSA</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>Not Married</td>\n      <td>Rent</td>\n      <td>Employed</td>\n      <td>bhuqouqj</td>\n      <td>MSA, Not Principle  City</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>pxcmvdjn</td>\n      <td>xgwztkwe</td>\n      <td>train</td>\n    </tr>\n  </tbody>\n</table>\n<p>2 rows × 36 columns</p>\n</div>"
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set `respondent_id` as index\n",
    "data = original_data.set_index(\"respondent_id\")\n",
    "training_labels = training_labels.set_index(\"respondent_id\")\n",
    "\n",
    "data.head(2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Look for columns with significant amt of null values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 26707 entries, 0 to 26706\n",
      "Data columns (total 36 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   h1n1_concern                 26615 non-null  float64\n",
      " 1   h1n1_knowledge               26591 non-null  float64\n",
      " 2   behavioral_antiviral_meds    26636 non-null  float64\n",
      " 3   behavioral_avoidance         26499 non-null  float64\n",
      " 4   behavioral_face_mask         26688 non-null  float64\n",
      " 5   behavioral_wash_hands        26665 non-null  float64\n",
      " 6   behavioral_large_gatherings  26620 non-null  float64\n",
      " 7   behavioral_outside_home      26625 non-null  float64\n",
      " 8   behavioral_touch_face        26579 non-null  float64\n",
      " 9   doctor_recc_h1n1             24547 non-null  float64\n",
      " 10  doctor_recc_seasonal         24547 non-null  float64\n",
      " 11  chronic_med_condition        25736 non-null  float64\n",
      " 12  child_under_6_months         25887 non-null  float64\n",
      " 13  health_worker                25903 non-null  float64\n",
      " 14  health_insurance             14433 non-null  float64\n",
      " 15  opinion_h1n1_vacc_effective  26316 non-null  float64\n",
      " 16  opinion_h1n1_risk            26319 non-null  float64\n",
      " 17  opinion_h1n1_sick_from_vacc  26312 non-null  float64\n",
      " 18  opinion_seas_vacc_effective  26245 non-null  float64\n",
      " 19  opinion_seas_risk            26193 non-null  float64\n",
      " 20  opinion_seas_sick_from_vacc  26170 non-null  float64\n",
      " 21  age_group                    26707 non-null  object \n",
      " 22  education                    25300 non-null  object \n",
      " 23  race                         26707 non-null  object \n",
      " 24  sex                          26707 non-null  object \n",
      " 25  income_poverty               22284 non-null  object \n",
      " 26  marital_status               25299 non-null  object \n",
      " 27  rent_or_own                  24665 non-null  object \n",
      " 28  employment_status            25244 non-null  object \n",
      " 29  hhs_geo_region               26707 non-null  object \n",
      " 30  census_msa                   26707 non-null  object \n",
      " 31  household_adults             26458 non-null  float64\n",
      " 32  household_children           26458 non-null  float64\n",
      " 33  employment_industry          13377 non-null  object \n",
      " 34  employment_occupation        13237 non-null  object \n",
      " 35  type                         26707 non-null  object \n",
      "dtypes: float64(23), object(13)\n",
      "memory usage: 7.5+ MB\n"
     ]
    }
   ],
   "source": [
    "data.loc[data[\"type\"] == \"train\"].info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "I can see that following in training data have severely missing values:\n",
    "1. health_insurance\n",
    "2. employment_industry\n",
    "3. employment_occupation\n",
    "\n",
    "I'm doing the same for test data to see if they match"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 26708 entries, 26707 to 53414\n",
      "Data columns (total 36 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   h1n1_concern                 26623 non-null  float64\n",
      " 1   h1n1_knowledge               26586 non-null  float64\n",
      " 2   behavioral_antiviral_meds    26629 non-null  float64\n",
      " 3   behavioral_avoidance         26495 non-null  float64\n",
      " 4   behavioral_face_mask         26689 non-null  float64\n",
      " 5   behavioral_wash_hands        26668 non-null  float64\n",
      " 6   behavioral_large_gatherings  26636 non-null  float64\n",
      " 7   behavioral_outside_home      26626 non-null  float64\n",
      " 8   behavioral_touch_face        26580 non-null  float64\n",
      " 9   doctor_recc_h1n1             24548 non-null  float64\n",
      " 10  doctor_recc_seasonal         24548 non-null  float64\n",
      " 11  chronic_med_condition        25776 non-null  float64\n",
      " 12  child_under_6_months         25895 non-null  float64\n",
      " 13  health_worker                25919 non-null  float64\n",
      " 14  health_insurance             14480 non-null  float64\n",
      " 15  opinion_h1n1_vacc_effective  26310 non-null  float64\n",
      " 16  opinion_h1n1_risk            26328 non-null  float64\n",
      " 17  opinion_h1n1_sick_from_vacc  26333 non-null  float64\n",
      " 18  opinion_seas_vacc_effective  26256 non-null  float64\n",
      " 19  opinion_seas_risk            26209 non-null  float64\n",
      " 20  opinion_seas_sick_from_vacc  26187 non-null  float64\n",
      " 21  age_group                    26708 non-null  object \n",
      " 22  education                    25301 non-null  object \n",
      " 23  race                         26708 non-null  object \n",
      " 24  sex                          26708 non-null  object \n",
      " 25  income_poverty               22211 non-null  object \n",
      " 26  marital_status               25266 non-null  object \n",
      " 27  rent_or_own                  24672 non-null  object \n",
      " 28  employment_status            25237 non-null  object \n",
      " 29  hhs_geo_region               26708 non-null  object \n",
      " 30  census_msa                   26708 non-null  object \n",
      " 31  household_adults             26483 non-null  float64\n",
      " 32  household_children           26483 non-null  float64\n",
      " 33  employment_industry          13433 non-null  object \n",
      " 34  employment_occupation        13282 non-null  object \n",
      " 35  type                         26708 non-null  object \n",
      "dtypes: float64(23), object(13)\n",
      "memory usage: 7.5+ MB\n"
     ]
    }
   ],
   "source": [
    "data.loc[data[\"type\"] == \"test\"].info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here in test data also following have missing values\n",
    "1. health_insurance\n",
    "2. employment_industry\n",
    "3. employment_occupation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "data": {
      "text/plain": "               h1n1_concern  h1n1_knowledge  behavioral_antiviral_meds  \\\nrespondent_id                                                            \n0                       1.0             0.0                        0.0   \n1                       3.0             2.0                        0.0   \n2                       1.0             1.0                        0.0   \n3                       1.0             1.0                        0.0   \n4                       2.0             1.0                        0.0   \n...                     ...             ...                        ...   \n53410                   1.0             1.0                        0.0   \n53411                   3.0             1.0                        0.0   \n53412                   0.0             1.0                        0.0   \n53413                   3.0             1.0                        0.0   \n53414                   2.0             1.0                        0.0   \n\n               behavioral_avoidance  behavioral_face_mask  \\\nrespondent_id                                               \n0                               0.0                   0.0   \n1                               1.0                   0.0   \n2                               1.0                   0.0   \n3                               1.0                   0.0   \n4                               1.0                   0.0   \n...                             ...                   ...   \n53410                           1.0                   0.0   \n53411                           1.0                   0.0   \n53412                           0.0                   0.0   \n53413                           1.0                   0.0   \n53414                           0.0                   0.0   \n\n               behavioral_wash_hands  behavioral_large_gatherings  \\\nrespondent_id                                                       \n0                                0.0                          0.0   \n1                                1.0                          0.0   \n2                                0.0                          0.0   \n3                                1.0                          1.0   \n4                                1.0                          1.0   \n...                              ...                          ...   \n53410                            1.0                          0.0   \n53411                            1.0                          1.0   \n53412                            0.0                          0.0   \n53413                            1.0                          0.0   \n53414                            1.0                          0.0   \n\n               behavioral_outside_home  behavioral_touch_face  \\\nrespondent_id                                                   \n0                                  1.0                    1.0   \n1                                  1.0                    1.0   \n2                                  0.0                    0.0   \n3                                  0.0                    0.0   \n4                                  0.0                    1.0   \n...                                ...                    ...   \n53410                              0.0                    1.0   \n53411                              1.0                    1.0   \n53412                              0.0                    0.0   \n53413                              1.0                    0.0   \n53414                              0.0                    1.0   \n\n               doctor_recc_h1n1  ...             income_poverty  \\\nrespondent_id                    ...                              \n0                           0.0  ...              Below Poverty   \n1                           0.0  ...              Below Poverty   \n2                           NaN  ...  <= $75,000, Above Poverty   \n3                           0.0  ...              Below Poverty   \n4                           0.0  ...  <= $75,000, Above Poverty   \n...                         ...  ...                        ...   \n53410                       1.0  ...                        NaN   \n53411                       0.0  ...              Below Poverty   \n53412                       0.0  ...              Below Poverty   \n53413                       0.0  ...  <= $75,000, Above Poverty   \n53414                       1.0  ...                        NaN   \n\n               marital_status  rent_or_own   employment_status  \\\nrespondent_id                                                    \n0                 Not Married          Own  Not in Labor Force   \n1                 Not Married         Rent            Employed   \n2                 Not Married          Own            Employed   \n3                 Not Married         Rent  Not in Labor Force   \n4                     Married          Own            Employed   \n...                       ...          ...                 ...   \n53410                     NaN          NaN                 NaN   \n53411                 Married         Rent            Employed   \n53412             Not Married         Rent  Not in Labor Force   \n53413                 Married          Own  Not in Labor Force   \n53414             Not Married         Rent            Employed   \n\n               hhs_geo_region                census_msa  household_adults  \\\nrespondent_id                                                               \n0                    oxchjgsf                   Non-MSA               0.0   \n1                    bhuqouqj  MSA, Not Principle  City               0.0   \n2                    qufhixun  MSA, Not Principle  City               2.0   \n3                    lrircsnp       MSA, Principle City               0.0   \n4                    qufhixun  MSA, Not Principle  City               1.0   \n...                       ...                       ...               ...   \n53410                dqpwygqj       MSA, Principle City               1.0   \n53411                qufhixun                   Non-MSA               1.0   \n53412                qufhixun  MSA, Not Principle  City               1.0   \n53413                bhuqouqj  MSA, Not Principle  City               1.0   \n53414                lrircsnp       MSA, Principle City               0.0   \n\n               household_children  employment_industry   type  \nrespondent_id                                                  \n0                             0.0                  NaN  train  \n1                             0.0             pxcmvdjn  train  \n2                             0.0             rucpziij  train  \n3                             0.0                  NaN  train  \n4                             0.0             wxleyezf  train  \n...                           ...                  ...    ...  \n53410                         1.0                  NaN   test  \n53411                         3.0             fcxhlnwr   test  \n53412                         0.0                  NaN   test  \n53413                         0.0                  NaN   test  \n53414                         0.0                  NaN   test  \n\n[53415 rows x 35 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>h1n1_concern</th>\n      <th>h1n1_knowledge</th>\n      <th>behavioral_antiviral_meds</th>\n      <th>behavioral_avoidance</th>\n      <th>behavioral_face_mask</th>\n      <th>behavioral_wash_hands</th>\n      <th>behavioral_large_gatherings</th>\n      <th>behavioral_outside_home</th>\n      <th>behavioral_touch_face</th>\n      <th>doctor_recc_h1n1</th>\n      <th>...</th>\n      <th>income_poverty</th>\n      <th>marital_status</th>\n      <th>rent_or_own</th>\n      <th>employment_status</th>\n      <th>hhs_geo_region</th>\n      <th>census_msa</th>\n      <th>household_adults</th>\n      <th>household_children</th>\n      <th>employment_industry</th>\n      <th>type</th>\n    </tr>\n    <tr>\n      <th>respondent_id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>Below Poverty</td>\n      <td>Not Married</td>\n      <td>Own</td>\n      <td>Not in Labor Force</td>\n      <td>oxchjgsf</td>\n      <td>Non-MSA</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>Below Poverty</td>\n      <td>Not Married</td>\n      <td>Rent</td>\n      <td>Employed</td>\n      <td>bhuqouqj</td>\n      <td>MSA, Not Principle  City</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>pxcmvdjn</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>&lt;= $75,000, Above Poverty</td>\n      <td>Not Married</td>\n      <td>Own</td>\n      <td>Employed</td>\n      <td>qufhixun</td>\n      <td>MSA, Not Principle  City</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>rucpziij</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>Below Poverty</td>\n      <td>Not Married</td>\n      <td>Rent</td>\n      <td>Not in Labor Force</td>\n      <td>lrircsnp</td>\n      <td>MSA, Principle City</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>&lt;= $75,000, Above Poverty</td>\n      <td>Married</td>\n      <td>Own</td>\n      <td>Employed</td>\n      <td>qufhixun</td>\n      <td>MSA, Not Principle  City</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>wxleyezf</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>53410</th>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>dqpwygqj</td>\n      <td>MSA, Principle City</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>test</td>\n    </tr>\n    <tr>\n      <th>53411</th>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>Below Poverty</td>\n      <td>Married</td>\n      <td>Rent</td>\n      <td>Employed</td>\n      <td>qufhixun</td>\n      <td>Non-MSA</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>fcxhlnwr</td>\n      <td>test</td>\n    </tr>\n    <tr>\n      <th>53412</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>Below Poverty</td>\n      <td>Not Married</td>\n      <td>Rent</td>\n      <td>Not in Labor Force</td>\n      <td>qufhixun</td>\n      <td>MSA, Not Principle  City</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>test</td>\n    </tr>\n    <tr>\n      <th>53413</th>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>&lt;= $75,000, Above Poverty</td>\n      <td>Married</td>\n      <td>Own</td>\n      <td>Not in Labor Force</td>\n      <td>bhuqouqj</td>\n      <td>MSA, Not Principle  City</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>test</td>\n    </tr>\n    <tr>\n      <th>53414</th>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>Not Married</td>\n      <td>Rent</td>\n      <td>Employed</td>\n      <td>lrircsnp</td>\n      <td>MSA, Principle City</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>test</td>\n    </tr>\n  </tbody>\n</table>\n<p>53415 rows × 35 columns</p>\n</div>"
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # im dropping those columns\n",
    "# \n",
    "# data.drop(\"health_insurance\", axis=1)\n",
    "# data.drop(\"employment_industry\", axis=1)\n",
    "# data.drop(\"employment_occupation\", axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Encoding categorical data\n",
    "\n",
    "This was not done in `attempt_1_170020C`. I am going with LabelEncoder to encode categorical features.\n",
    "For that, I need to know what are the categorical features.\n",
    "\n",
    "#### Identifying categorical columns and numerical columns\n",
    "\n",
    "I need to identify categorical columns and unique values for each column."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age_group:\t['55 - 64 Years' '35 - 44 Years' '18 - 34 Years' '65+ Years'\n",
      " '45 - 54 Years']\n",
      "education:\t['< 12 Years' '12 Years' 'College Graduate' 'Some College' nan]\n",
      "race:\t['White' 'Black' 'Other or Multiple' 'Hispanic']\n",
      "sex:\t['Female' 'Male']\n",
      "income_poverty:\t['Below Poverty' '<= $75,000, Above Poverty' '> $75,000' nan]\n",
      "marital_status:\t['Not Married' 'Married' nan]\n",
      "rent_or_own:\t['Own' 'Rent' nan]\n",
      "employment_status:\t['Not in Labor Force' 'Employed' 'Unemployed' nan]\n",
      "hhs_geo_region:\t['oxchjgsf' 'bhuqouqj' 'qufhixun' 'lrircsnp' 'atmpeygn' 'lzgpxyit'\n",
      " 'fpwskwrf' 'mlyzmhmf' 'dqpwygqj' 'kbazzjca']\n",
      "census_msa:\t['Non-MSA' 'MSA, Not Principle  City' 'MSA, Principle City']\n",
      "employment_industry:\t[nan 'pxcmvdjn' 'rucpziij' 'wxleyezf' 'saaquncn' 'xicduogh' 'ldnlellj'\n",
      " 'wlfvacwt' 'nduyfdeo' 'fcxhlnwr' 'vjjrobsf' 'arjwrbjb' 'atmlpfrs'\n",
      " 'msuufmds' 'xqicxuve' 'phxvnwax' 'dotnnunm' 'mfikgejo' 'cfqqtusy'\n",
      " 'mcubkhph' 'haxffmxo' 'qnlwzans']\n",
      "employment_occupation:\t[nan 'xgwztkwe' 'xtkaffoo' 'emcorrxb' 'vlluhbov' 'xqwwgdyp' 'ccgxvspp'\n",
      " 'qxajmpny' 'kldqjyjy' 'mxkfnird' 'hfxkjkmi' 'bxpfxfdn' 'ukymxvdu'\n",
      " 'cmhcxjea' 'haliazsg' 'dlvbwzss' 'xzmlyyjv' 'oijqvulv' 'rcertsgn'\n",
      " 'tfqavkke' 'hodpvpew' 'uqqtjvyb' 'pvmttkik' 'dcjcmpih']\n",
      "type:\t['train' 'test']\n"
     ]
    }
   ],
   "source": [
    "categorical_columns = np.where(data.dtypes == object)[0]\n",
    "\n",
    "categorical_features = [data.columns[feature] for feature in categorical_columns]\n",
    "numerical_features = [feature for feature in data.columns if feature not in categorical_features]\n",
    "\n",
    "for feature in categorical_features:\n",
    "    print(\"%s:\\t%s\" % (feature, str(data[feature].unique())))\n",
    "\n",
    "assert (len(categorical_features) + len(numerical_features) == len(data.columns))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As you can see, `employment_industry`, `hhs_geo_region` and `employment_occupation` are scrambled for privacy protection.\n",
    "However, I can still use those columns because, for my use case, knowing actual occupation or industry is not necessary.\n",
    "\n",
    "Now I can apply LabelEncoding to those columns, because `NaN` values are depicted as `NaN`\n",
    "\n",
    "#### Applying Label Encoding to categorical columns\n",
    "\n",
    "The problem with Native encoder is that it also encodes `NaN` values.\n",
    "I have to make sure `Nan` values are unaffected as I'll be sanitizing them later"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "data": {
      "text/plain": "               h1n1_concern  h1n1_knowledge  behavioral_antiviral_meds  \\\nrespondent_id                                                            \n53413                   3.0             1.0                        0.0   \n53414                   2.0             1.0                        0.0   \n\n               behavioral_avoidance  behavioral_face_mask  \\\nrespondent_id                                               \n53413                           1.0                   0.0   \n53414                           0.0                   0.0   \n\n               behavioral_wash_hands  behavioral_large_gatherings  \\\nrespondent_id                                                       \n53413                            1.0                          0.0   \n53414                            1.0                          0.0   \n\n               behavioral_outside_home  behavioral_touch_face  \\\nrespondent_id                                                   \n53413                              1.0                    0.0   \n53414                              0.0                    1.0   \n\n               doctor_recc_h1n1  ...  marital_status  rent_or_own  \\\nrespondent_id                    ...                                \n53413                       0.0  ...             1.0          0.0   \n53414                       1.0  ...             0.0          1.0   \n\n               employment_status  hhs_geo_region  census_msa  \\\nrespondent_id                                                  \n53413                        0.0             1.0         1.0   \n53414                        1.0             3.0         2.0   \n\n               household_adults  household_children  employment_industry  \\\nrespondent_id                                                              \n53413                       1.0                 0.0                  NaN   \n53414                       0.0                 0.0                  NaN   \n\n               employment_occupation  type  \nrespondent_id                               \n53413                            NaN  test  \n53414                            2.0  test  \n\n[2 rows x 36 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>h1n1_concern</th>\n      <th>h1n1_knowledge</th>\n      <th>behavioral_antiviral_meds</th>\n      <th>behavioral_avoidance</th>\n      <th>behavioral_face_mask</th>\n      <th>behavioral_wash_hands</th>\n      <th>behavioral_large_gatherings</th>\n      <th>behavioral_outside_home</th>\n      <th>behavioral_touch_face</th>\n      <th>doctor_recc_h1n1</th>\n      <th>...</th>\n      <th>marital_status</th>\n      <th>rent_or_own</th>\n      <th>employment_status</th>\n      <th>hhs_geo_region</th>\n      <th>census_msa</th>\n      <th>household_adults</th>\n      <th>household_children</th>\n      <th>employment_industry</th>\n      <th>employment_occupation</th>\n      <th>type</th>\n    </tr>\n    <tr>\n      <th>respondent_id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>53413</th>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>test</td>\n    </tr>\n    <tr>\n      <th>53414</th>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>test</td>\n    </tr>\n  </tbody>\n</table>\n<p>2 rows × 36 columns</p>\n</div>"
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder, data = LabelEncoderWithMissingValues().categorical_to_numeric(data, ignored=['type'])\n",
    "\n",
    "assert(data.shape[1] == original_data.shape[1] - 1)\n",
    "\n",
    "data.tail(2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As you can see `data` is now encoded with the exception of `type` column.\n",
    "The type column will be later used to divide `data` into `train` and\n",
    "`test`\n",
    "\n",
    "### Filling missing values\n",
    "\n",
    "I want to use Nearest Neighbor Imputation to fill `NaN` values\n",
    "\n",
    "#### Normalizing data\n",
    "\n",
    "KNN Imputer is distance based, and hence data should be normalized beforehand to avoid\n",
    "bias."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "data": {
      "text/plain": "   h1n1_concern  h1n1_knowledge  behavioral_antiviral_meds  \\\n0      0.333333             0.0                        0.0   \n1      1.000000             1.0                        0.0   \n2      0.333333             0.5                        0.0   \n3      0.333333             0.5                        0.0   \n4      0.666667             0.5                        0.0   \n\n   behavioral_avoidance  behavioral_face_mask  behavioral_wash_hands  \\\n0                   0.0                   0.0                    0.0   \n1                   1.0                   0.0                    1.0   \n2                   1.0                   0.0                    0.0   \n3                   1.0                   0.0                    1.0   \n4                   1.0                   0.0                    1.0   \n\n   behavioral_large_gatherings  behavioral_outside_home  \\\n0                          0.0                      1.0   \n1                          0.0                      1.0   \n2                          0.0                      0.0   \n3                          1.0                      0.0   \n4                          1.0                      0.0   \n\n   behavioral_touch_face  doctor_recc_h1n1  ...  income_poverty  \\\n0                    1.0               0.0  ...             0.0   \n1                    1.0               0.0  ...             0.0   \n2                    0.0               NaN  ...             0.5   \n3                    0.0               0.0  ...             0.0   \n4                    1.0               0.0  ...             0.5   \n\n   marital_status  rent_or_own  employment_status  hhs_geo_region  census_msa  \\\n0             0.0          0.0                0.0        0.000000         0.0   \n1             0.0          1.0                0.5        0.111111         0.5   \n2             0.0          0.0                0.5        0.222222         0.5   \n3             0.0          1.0                0.0        0.333333         1.0   \n4             1.0          0.0                0.5        0.222222         0.5   \n\n   household_adults  household_children  employment_industry  \\\n0          0.000000                 0.0                  NaN   \n1          0.000000                 0.0                 0.00   \n2          0.666667                 0.0                 0.05   \n3          0.000000                 0.0                  NaN   \n4          0.333333                 0.0                 0.10   \n\n   employment_occupation  \n0                    NaN  \n1               0.000000  \n2               0.045455  \n3                    NaN  \n4               0.090909  \n\n[5 rows x 35 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>h1n1_concern</th>\n      <th>h1n1_knowledge</th>\n      <th>behavioral_antiviral_meds</th>\n      <th>behavioral_avoidance</th>\n      <th>behavioral_face_mask</th>\n      <th>behavioral_wash_hands</th>\n      <th>behavioral_large_gatherings</th>\n      <th>behavioral_outside_home</th>\n      <th>behavioral_touch_face</th>\n      <th>doctor_recc_h1n1</th>\n      <th>...</th>\n      <th>income_poverty</th>\n      <th>marital_status</th>\n      <th>rent_or_own</th>\n      <th>employment_status</th>\n      <th>hhs_geo_region</th>\n      <th>census_msa</th>\n      <th>household_adults</th>\n      <th>household_children</th>\n      <th>employment_industry</th>\n      <th>employment_occupation</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.333333</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.000000</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.5</td>\n      <td>0.111111</td>\n      <td>0.5</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.333333</td>\n      <td>0.5</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>0.5</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.5</td>\n      <td>0.222222</td>\n      <td>0.5</td>\n      <td>0.666667</td>\n      <td>0.0</td>\n      <td>0.05</td>\n      <td>0.045455</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.333333</td>\n      <td>0.5</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.333333</td>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.666667</td>\n      <td>0.5</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.5</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.5</td>\n      <td>0.222222</td>\n      <td>0.5</td>\n      <td>0.333333</td>\n      <td>0.0</td>\n      <td>0.10</td>\n      <td>0.090909</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 35 columns</p>\n</div>"
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = data.drop(\"type\", axis=1)\n",
    "\n",
    "scalar = MinMaxScaler()\n",
    "temp = pd.DataFrame(scalar.fit_transform(temp), columns=temp.columns)\n",
    "\n",
    "# note that `temp` has column `type` missing\n",
    "temp.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Utilizing KNN Imputer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "data": {
      "text/plain": "       h1n1_concern  h1n1_knowledge  behavioral_antiviral_meds  \\\n53410      0.333333             0.5                        0.0   \n53411      1.000000             0.5                        0.0   \n53412      0.000000             0.5                        0.0   \n53413      1.000000             0.5                        0.0   \n53414      0.666667             0.5                        0.0   \n\n       behavioral_avoidance  behavioral_face_mask  behavioral_wash_hands  \\\n53410                   1.0                   0.0                    1.0   \n53411                   1.0                   0.0                    1.0   \n53412                   0.0                   0.0                    0.0   \n53413                   1.0                   0.0                    1.0   \n53414                   0.0                   0.0                    1.0   \n\n       behavioral_large_gatherings  behavioral_outside_home  \\\n53410                          0.0                      0.0   \n53411                          1.0                      1.0   \n53412                          0.0                      0.0   \n53413                          0.0                      1.0   \n53414                          0.0                      0.0   \n\n       behavioral_touch_face  doctor_recc_h1n1  ...  marital_status  \\\n53410                    1.0               1.0  ...             1.0   \n53411                    1.0               0.0  ...             1.0   \n53412                    0.0               0.0  ...             0.0   \n53413                    0.0               0.0  ...             1.0   \n53414                    1.0               1.0  ...             0.0   \n\n       rent_or_own  employment_status  hhs_geo_region  census_msa  \\\n53410          0.0                0.5        0.888889         1.0   \n53411          1.0                0.5        0.222222         0.0   \n53412          1.0                0.0        0.222222         0.5   \n53413          0.0                0.0        0.111111         0.5   \n53414          1.0                0.5        0.333333         1.0   \n\n       household_adults  household_children  employment_industry  \\\n53410          0.333333            0.333333                  0.9   \n53411          0.333333            1.000000                  0.4   \n53412          0.333333            0.000000                  0.1   \n53413          0.333333            0.000000                  0.8   \n53414          0.000000            0.000000                  0.0   \n\n       employment_occupation  type  \n53410               0.363636  test  \n53411               0.136364  test  \n53412               0.409091  test  \n53413               0.363636  test  \n53414               0.045455  test  \n\n[5 rows x 36 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>h1n1_concern</th>\n      <th>h1n1_knowledge</th>\n      <th>behavioral_antiviral_meds</th>\n      <th>behavioral_avoidance</th>\n      <th>behavioral_face_mask</th>\n      <th>behavioral_wash_hands</th>\n      <th>behavioral_large_gatherings</th>\n      <th>behavioral_outside_home</th>\n      <th>behavioral_touch_face</th>\n      <th>doctor_recc_h1n1</th>\n      <th>...</th>\n      <th>marital_status</th>\n      <th>rent_or_own</th>\n      <th>employment_status</th>\n      <th>hhs_geo_region</th>\n      <th>census_msa</th>\n      <th>household_adults</th>\n      <th>household_children</th>\n      <th>employment_industry</th>\n      <th>employment_occupation</th>\n      <th>type</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>53410</th>\n      <td>0.333333</td>\n      <td>0.5</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.5</td>\n      <td>0.888889</td>\n      <td>1.0</td>\n      <td>0.333333</td>\n      <td>0.333333</td>\n      <td>0.9</td>\n      <td>0.363636</td>\n      <td>test</td>\n    </tr>\n    <tr>\n      <th>53411</th>\n      <td>1.000000</td>\n      <td>0.5</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.5</td>\n      <td>0.222222</td>\n      <td>0.0</td>\n      <td>0.333333</td>\n      <td>1.000000</td>\n      <td>0.4</td>\n      <td>0.136364</td>\n      <td>test</td>\n    </tr>\n    <tr>\n      <th>53412</th>\n      <td>0.000000</td>\n      <td>0.5</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.222222</td>\n      <td>0.5</td>\n      <td>0.333333</td>\n      <td>0.000000</td>\n      <td>0.1</td>\n      <td>0.409091</td>\n      <td>test</td>\n    </tr>\n    <tr>\n      <th>53413</th>\n      <td>1.000000</td>\n      <td>0.5</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.111111</td>\n      <td>0.5</td>\n      <td>0.333333</td>\n      <td>0.000000</td>\n      <td>0.8</td>\n      <td>0.363636</td>\n      <td>test</td>\n    </tr>\n    <tr>\n      <th>53414</th>\n      <td>0.666667</td>\n      <td>0.5</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.5</td>\n      <td>0.333333</td>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.045455</td>\n      <td>test</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 36 columns</p>\n</div>"
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# got the neighbour value `n_neighbors` from `attempt_1_170020C`\n",
    "imputer = KNNImputer(n_neighbors=1)\n",
    "\n",
    "temp = pd.DataFrame(imputer.fit_transform(temp), columns=temp.columns)\n",
    "\n",
    "temp[\"type\"] = data[\"type\"]\n",
    "data = temp\n",
    "\n",
    "assert (not any(data.isna().any()))\n",
    "\n",
    "data.tail()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Attempting to sort with Random Forest Classifier\n",
    "\n",
    "This is new attempt from `attempt_2_170020C`\n",
    "\n",
    "### Define targets and train, test data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "target_h1n1_vaccine = training_labels[\"h1n1_vaccine\"].values\n",
    "target_seasonal_vaccine = training_labels[\"seasonal_vaccine\"].values\n",
    "\n",
    "train_data = data[data.type.eq(\"train\")].drop(\"type\", axis=1)\n",
    "test_data = data[data.type.eq(\"test\")].drop(\"type\", axis=1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Split train data into train and test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "# split in 80:20 ratio\n",
    "# because of two separate train and test scenarios, I'm using different names rather than use X_train, X_test...\n",
    "p_train, p_test, q_train, q_test = train_test_split(train_data, target_h1n1_vaccine, test_size=0.2, random_state=1, stratify=target_h1n1_vaccine)\n",
    "r_train, r_test, s_train, s_test = train_test_split(train_data, target_seasonal_vaccine, test_size=0.2, random_state=1, stratify=target_seasonal_vaccine)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Use Random Search CV\n",
    "\n",
    "I'll be commenting out the code because I have already ran it once and\n",
    "don't want to waste running time"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Use RandomSearchCV to determine K value for each\n",
    "\n",
    "random_grid = {\n",
    "    # 'n_estimators': [n for n in range(1, max_val) if n % 10 == 0],\n",
    "    # 'max_features': ['auto', 'sqrt'],\n",
    "    # 'max_depth': [n for n in range(0, max_val) if n % 10 == 0] + [None],\n",
    "    # 'min_samples_split': [n for n in range(0, 30) if n % 2 == 0],\n",
    "    # 'min_samples_leaf': [n for n in range(0, 30) if n % 2 == 0],\n",
    "    # 'bootstrap': [True, False]\n",
    "\n",
    "    'n_estimators': [n for n in range(1, 1000) if n % 10 == 0],\n",
    "    'max_features': ['sqrt'],\n",
    "    'max_depth': [n for n in range(50, 150) if n % 10 == 0] + [None],\n",
    "    'min_samples_split': [n for n in range(1, 40) if n % 2 == 0],\n",
    "    'min_samples_leaf': [n for n in range(1, 20) if n % 2 == 0],\n",
    "    'bootstrap': [False]\n",
    "}\n",
    "\n",
    "rscv = RandomizedSearchCV(\n",
    "    estimator = RandomForestClassifier(),\n",
    "    param_distributions = random_grid,\n",
    "    n_iter=100,\n",
    "    cv=None,\n",
    "    verbose=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"Ready\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 65,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "# # for h1n1 vaccine\n",
    "#\n",
    "# rscv.fit(p_train, q_train)\n",
    "#\n",
    "# print(rscv.best_params_)\n",
    "# print(rscv.best_score_)\n",
    "#\n",
    "# print(\"Finished\")\n",
    "\n",
    "# already done. see below for results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The optimal parameters for \"h1n1\" are:\n",
    "1. 'n_estimators': 775\n",
    "2. 'max_features': sqrt\n",
    "3. 'max_depth': 90\n",
    "4. 'min_samples_split': 14\n",
    "5. 'min_samples_leaf': 2\n",
    "6. 'bootstrap': False\n",
    "\n",
    "{'n_estimators': 770, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': 140, 'bootstrap': False}\n",
    "0.8325299604752726\n",
    "\n",
    "{'n_estimators': 790, 'min_samples_split': 28, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'max_depth': 20, 'bootstrap': False}\n",
    "0.8329044331425012\n",
    "\n",
    "{'n_estimators': 775, 'min_samples_split': 14, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': 90, 'bootstrap': False}\n",
    "0.8346828925813246 => This seems to be the best overall"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "# # for seasonal vaccine\n",
    "# rscv.fit(r_train, s_train)\n",
    "#\n",
    "# print(rscv.best_params_)\n",
    "# print(rscv.best_score_)\n",
    "#\n",
    "# print(\"Finished\")\n",
    "\n",
    "# already done. see below for results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The optimal parameters for \"h1n1\" are:\n",
    "1. 'n_estimators': 650\n",
    "2. 'max_features': sqrt\n",
    "3. 'max_depth': 120\n",
    "4. 'min_samples_split': 34\n",
    "5. 'min_samples_leaf': 2\n",
    "6. 'bootstrap': False\n",
    "\n",
    "{'n_estimators': 650, 'min_samples_split': 34, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': 120, 'bootstrap': False}\n",
    "0.7750058506903815"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train with RandomForestClassifier"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H1N1 Fit complete\n"
     ]
    }
   ],
   "source": [
    "# 1. Do for h1n1 vaccine\n",
    "\n",
    "rfc_h1n1 = RandomForestClassifier(\n",
    "    n_estimators=775,\n",
    "    max_features=\"sqrt\",\n",
    "    max_depth=90,\n",
    "    min_samples_split=14,\n",
    "    min_samples_leaf=2,\n",
    "    bootstrap=False\n",
    ")\n",
    "rfc_h1n1.fit(p_train, q_train)\n",
    "print(\"H1N1 Fit complete\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "data": {
      "text/plain": "0.8384500187195807"
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_h1n1.score(p_test, q_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seasonal Fit complete\n"
     ]
    }
   ],
   "source": [
    "# 2. Do for seasonal vaccine\n",
    "\n",
    "rfc_seasonal = RandomForestClassifier(\n",
    "    n_estimators=650,\n",
    "    max_features='sqrt',\n",
    "    max_depth=120,\n",
    "    min_samples_split=34,\n",
    "    min_samples_leaf=2,\n",
    "    bootstrap=False\n",
    ")\n",
    "rfc_seasonal.fit(r_train, s_train)\n",
    "print(\"Seasonal Fit complete\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "data": {
      "text/plain": "0.7854736053912392"
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_seasonal.score(r_test, s_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Execute model on given test data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "data": {
      "text/plain": "   respondent_id  h1n1_vaccine  seasonal_vaccine\n0          26707             0                 0\n1          26708             0                 0\n2          26709             0                 1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>respondent_id</th>\n      <th>h1n1_vaccine</th>\n      <th>seasonal_vaccine</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>26707</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>26708</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>26709</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "build = pd.DataFrame(original_test[\"respondent_id\"])\n",
    "\n",
    "result_h1n1 = rfc_h1n1.predict(test_data)\n",
    "build[\"h1n1_vaccine\"] = result_h1n1\n",
    "\n",
    "result_seasonal = rfc_seasonal.predict(test_data)\n",
    "build[\"seasonal_vaccine\"] = result_seasonal\n",
    "\n",
    "assert (build.shape == (26708, 3))\n",
    "\n",
    "build.head(3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Format the table and save it as a csv file"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [
    "# convert to a csv file\n",
    "\n",
    "# they require float values\n",
    "build.h1n1_vaccine = build.h1n1_vaccine.astype(float)\n",
    "build.seasonal_vaccine = build.seasonal_vaccine.astype(float)\n",
    "\n",
    "build.to_csv(\"output.csv\", index=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}